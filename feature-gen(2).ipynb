{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":420,"sourceType":"datasetVersion","datasetId":19},{"sourceId":2286,"sourceType":"datasetVersion","datasetId":1275},{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310},{"sourceId":256873,"sourceType":"datasetVersion","datasetId":107706},{"sourceId":346098,"sourceType":"datasetVersion","datasetId":149550},{"sourceId":1263738,"sourceType":"datasetVersion","datasetId":727551},{"sourceId":1938459,"sourceType":"datasetVersion","datasetId":1111894},{"sourceId":2650913,"sourceType":"datasetVersion","datasetId":1612087},{"sourceId":2879186,"sourceType":"datasetVersion","datasetId":826163},{"sourceId":3846912,"sourceType":"datasetVersion","datasetId":2289007},{"sourceId":4398600,"sourceType":"datasetVersion","datasetId":2580326},{"sourceId":8175771,"sourceType":"datasetVersion","datasetId":4839515},{"sourceId":11376681,"sourceType":"datasetVersion","datasetId":7122663},{"sourceId":12156348,"sourceType":"datasetVersion","datasetId":7474089}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\nfrom itertools import *\nimport seaborn as sns\nfrom matplotlib.pyplot import figure\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import mutual_info_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\nfrom sklearn.feature_selection import mutual_info_regression\n\nfrom sklearn.datasets import make_classification, make_regression\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import mutual_info_regression\nfrom scipy import stats\nfrom sklearn.metrics import classification_report\n","metadata":{"id":"VaE8UCJfPk-5","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Датасеты и обработка","metadata":{}},{"cell_type":"code","source":"\n#titanic = pd.read_csv(\"/kaggle/input/test-file/tested.csv\")\n#titanic = titanic.drop(columns=['Name','Cabin','Ticket'])\n#titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())\n#titanic['Fare'] = titanic['Fare'].fillna(titanic['Age'].median())\n#titanic = pd.get_dummies(titanic, dtype = int)\n#titanic = titanic[['Survived', 'Pclass', 'Age', 'SibSp', 'Fare']] \npd.set_option('future.no_silent_downcasting', True)\nincome = pd.read_csv(\"/kaggle/input/income-classification/income_evaluation.csv\")\nincome = income.replace({' <=50K':0,' >50K':1, ' Male':1, ' Female': 2})\nincome_tr = income[' income']\nincome_sex =  income[' sex']\nincome = income.drop(columns=[' native-country', ' income',  ' sex', ' marital-status'])\nincome['  workclass']= income[' workclass'].replace({' State-gov':'gov', ' Self-emp-not-inc':'Self-emp', ' Federal-gov':'gov',\n       ' Local-gov':'gov', ' Self-emp-inc':'Self-emp', ' Without-pay':'no work',\n       ' Never-worked':'no work'})\n\nincome[' education'] = income[' education'].replace(\n{' Bachelors': 'high', ' HS-grad':'HS', ' 11th':'HS','11th':'HS', ' Masters':'high', ' 9th':'low',\n       ' Some-college':'high', ' Assoc-acdm':'high', ' Assoc-voc':'high', ' 7th-8th':'low',\n       ' Doctorate':'high', ' Prof-school':'high', ' 5th-6th': 'low', ' 10th':'high', ' 1st-4th':'low',\n       ' Preschool':'low', ' 12th':'HS'})\n\n\nincome[' relationship'] = income[' relationship'].replace({' Not-in-family':'Unmarried', ' Husband':'married', ' Wife':'married', ' Own-child':'child', ' Unmarried':'Unmarried',\n       ' Other-relative':'Other'})\n\n\nincome = pd.get_dummies(income)\nincome[' sex'] = income_sex\nincome[' income'] = income_tr\n\nmarketing = pd.read_csv(\"/kaggle/input/marketing-campaign-positive-response-prediction/campaign_responses.csv\")\nmarketing = marketing.replace({'No':1, 'Yes':2, 'Male':1, 'Female':0, 'Married':1, 'Single':2})\nstudent = pd.read_csv(\"/kaggle/input/student-habits-vs-academic-performance/student_habits_performance.csv\")\nstudent = student.replace({'No':1, 'Yes':2, 'Female':1, 'Male':2})\nstudent['diet_quality'] = student['diet_quality'].replace({'Fair':2, 'Good':3, 'Poor':1})\nstudent['parental_education_level'] = student['parental_education_level'].replace({'Master':3, 'High School':1, 'Bachelor':2})\nstudent['internet_quality'] = student['internet_quality'].replace({'Average':2, 'Poor':1, 'Good':3})\nstudent = student.dropna()\nperson = pd.read_csv(\"/kaggle/input/extrovert-vs-introvert-behavior-data/personality_datasert.csv\")\nperson = person.replace({'No':1, 'Yes':2, 'Extrovert':1, 'Introvert':0})\nheart = pd.read_csv(\"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\nheart2 = pd.read_csv(\"/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv\")\niris = pd.read_csv('/kaggle/input/iris/Iris.csv')\ncreditfraud = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\nonlinefraud = pd.read_csv('/kaggle/input/online-payment-fraud-detection/onlinefraud.csv')\nonlinefraud = onlinefraud.drop(columns=['nameOrig','nameDest','isFlaggedFraud']) \nbankruptcy = pd.read_csv('/kaggle/input/company-bankruptcy-prediction/data.csv')\nb = bankruptcy['Bankrupt?']\nbankruptcy = bankruptcy.drop(columns=['Bankrupt?']) \nbankruptcy['Bankrupt?'] = b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:39:34.620434Z","iopub.execute_input":"2025-12-02T17:39:34.620763Z","iopub.status.idle":"2025-12-02T17:39:57.516748Z","shell.execute_reply.started":"2025-12-02T17:39:34.620740Z","shell.execute_reply":"2025-12-02T17:39:57.515850Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nclass Generator():\n\n    def __init__(self, X, y, n_columns = 2):\n       self.X = X\n       self.y = y\n       self.n_columns = n_columns # hiperparametr for generators witch split range of combination\n\n\n    def split_list_by_chunks(self, data, n_columns):\n        for i in range(0, len(data), self.n_columns ):\n            yield data[i:i + self.n_columns]\n\n    def multiply_gen(self, by=2, column_list=None): ## return np with annotation \n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by):\n            combinations_list.append(name_col)\n        \n        combinations_list = self.split_list_by_chunks(combinations_list, self.n_columns )\n        for seq in combinations_list:\n            B = np.empty((len(seq),self.X.shape[0]))\n            list_of_name = []\n            for i, tup in enumerate(seq):\n                A = np.ones(self.X.shape[0])\n                list_of_name.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n                for col in tup:\n                    A *= self.X[col].to_numpy()\n                B[i] = A\n            yield B, list_of_name\n \n\n    def multiply(self, by=2, column_list=None, with_all_data=True):  ## return dataframe \n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by):\n            combinations_list.append(name_col)      \n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            list_of_name.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n            for col in tup:\n                A *= self.X[col]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n        \n\n    def devision_on_last_gen(self, by=3, column_list=None):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, by):\n            combinations_list.append(name_col)\n        combinations_list = self.split_list_by_chunks(combinations_list, self.n_columns )\n\n        for seq in combinations_list:\n            B = np.empty((len(seq),self.X.shape[0]))\n            list_of_name = [] #'multiply and devision - '\n            for i, tup in enumerate(seq):\n                A = np.ones(self.X.shape[0])   \n                list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup[:-1])}, and devision on - {tup[-1]}')\n                for col in tup:\n                    A *= self.X[col].to_numpy()\n                    A = A/(self.X[tup[-1]]*self.X[tup[-1]])\n                B[i] = A\n            yield B, list_of_name\n\n\n         \n\n    def devision_on_last(self, by=3, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, by):\n            combinations_list.append(name_col)\n            \n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup[:-1])}, and devision on - {tup[-1]}')#.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n            for col in tup:\n                A *= self.X[col]\n                A = A/(self.X[tup[-1]]*self.X[tup[-1]])\n                B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n    \n            \n    def devision_in_pairs(self, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, 2):\n            combinations_list.append(name_col)\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            list_of_name.append(f'{str(tup[0])} // {str(tup[1])}')\n            A = X[tup[0]]/X[tup[1]]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n            \n\n\n    def log(self, column_list=None):\n        name_columns = self.X.columns if column_list == None else column_list\n        for col in name_columns:\n            X['log '+ str(col)] = np.log(X[col])    \n        df = X\n        return df\n        \n\n    def exp(self, column_list=None):\n        name_columns = self.X.columns if column_list == None else column_list\n        for col in name_columns:\n            X['exp '+ str(col)] = np.exp(X[col])    \n        df = X\n        return df\n\n    def degree(self, by=2, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, 2):\n            combinations_list.append(name_col)\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            #print(tup[0])\n            list_of_name.append(f'{str(tup[0])} ** {str(tup[1])}')\n            A = X[tup[0]]**X[tup[1]]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([self.X, self.y], axis=1)   \n        else:     \n            return df\n\n    def devision_on_last_2(self, by=3, column_list=None,  with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by-1):\n            combinations_list.append(name_col)\n        A = len(combinations_list)*(self.X.shape[1]-2)\n\n        \n        B = np.empty((A, self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            dev_sub = [el for el in name_columns if el not in tup]\n\n            for col in tup:\n                A *= self.X[col]\n                for dev in dev_sub:\n                    list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup)}, and devision on - {dev}')\n                    A = A/self.X[dev]\n                B[i] = A\n        list_of_name  = list(dict.fromkeys(list_of_name))\n\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n\n    def deltas(self, column_list=None,  with_all_data=True):\n        # use with standart scaler or normalize data only\n        name_columns = self.X.columns if column_list == None else column_list\n        combinations_list = []\n        for name_col in combinations(name_columns, 2):\n            combinations_list.append(name_col)\n        list_of_name = []\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        for i, tup in enumerate(combinations_list): \n            list_of_name.append(f'{str(tup[0])} - {str(tup[1])}')\n            B[i] = self.X[tup[0]]-self.X[tup[1]]\n        df = pd.DataFrame(B.T, columns=list_of_name) #?????\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n        \n    def sums():\n        pass\n  \n        \n\nclass Correlations():\n    def __init__(self, X, y):\n        self.X = X #2d dimentional df\n        self.y = y\n    \n\n    def mutual_info(self, mode='regression'):\n        mi_dict = {}\n        names_col = self.X.columns\n        if mode == 'regression':\n            v = mutual_info_regression(self.X, self.y)\n        else:\n             v = mutual_info_classif(self.X, self.y)\n        \n        for i, j in zip(names_col, v):\n            mi_dict[i]=j\n\n        mi_dict = dict(sorted(mi_dict.items(), key=lambda item: item[1]))\n        return mi_dict\n\n\n    def cramer_with_target(self):\n        corr_val_crammer = {}\n        for col in self.X.columns:\n            confusion_matrix = pd.crosstab(self.X[col], self.y)\n            chi2 = stats.chi2_contingency(confusion_matrix)[0]\n            n = confusion_matrix.sum().sum()\n            r, c = confusion_matrix.shape\n            min_dim = min(r - 1, c - 1)\n            v = np.sqrt(chi2 / (n * min_dim))\n            corr_val_crammer['crammer with target ' + col]= v\n        return corr_val_crammer\n\n\n    def correlation(self, name='pearsonr'):\n        corr_val = {}\n        for col in self.X.columns:\n            if name == 'pearsonr':\n                res = stats.pearsonr(self.X[col], self.y)\n            elif name == 'spearmanr': #Спирмен может быть полезна для нелинейных зависимостей.\n                res = stats.spearmanr(self.X[col], self.y)\n            elif name == 'kendalltau': #Кендалла, также используемой для ранговых данных\n                res = stats.kendalltau(self.X[col], self.y)\n            corr_val[col+' '+name] = res[0]\n        return corr_val\n\n    def heat_map(self):\n        co_mtx = self.X.corr(numeric_only=True)\n        w = co_mtx.shape[0]\n\n        figure(figsize=(w, w), dpi=80)\n        # Plot correlation heatmap\n        sns.heatmap(co_mtx, cmap=\"YlGnBu\", annot=True)\n\n\n\n    def corr_feature_analisys(self):\n        cor_dict = {}\n        names = self.X.columns\n        combinations_list = []\n        for name_col in combinations(names, 2):\n            combinations_list.append(name_col)\n\n        for pairs in combinations_list:\n            stat, _ = stats.pearsonr(self.X[pairs[0]], self.X[pairs[1]])\n            cor_dict[pairs] = stat\n        cor_dict = sorted(cor_dict.items(), key=lambda item: item[1], reverse=True)\n        cor_dict = dict(cor_dict)\n\n        return cor_dict\n\n    def vis_corr_feature_analisys(self):\n        cor_dict = self.corr_feature_analisys()\n        keys = [' '.join(el) for el in cor_dict.keys()]\n        #print(keys[:3], type(keys[2]))\n        #for el in cor_dict.keys():\n         #   cor_dict ', '.join(el)\n        vals = [float(v) for v in cor_dict.values()]#[float(cor_dict.values()) for k in keys]\n        #print(vals, keys)\n        w = len(keys)\n\n        figure(figsize=(w, w), dpi=80)\n        sns.catplot(x=vals, y=keys)\n  \n        \n        \n    def report_cor():\n        #p = correlation()\n        #s = correlation()\n        #k= correlation()\n        pass\n\n    def visulisation():\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:40:12.700877Z","iopub.execute_input":"2025-12-02T17:40:12.701712Z","iopub.status.idle":"2025-12-02T17:40:12.741578Z","shell.execute_reply.started":"2025-12-02T17:40:12.701676Z","shell.execute_reply":"2025-12-02T17:40:12.740708Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pipe for education and comparison","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_test_scaller(df, name=''):\n    \n    y = df[name]\n    X = df.drop([name], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=99)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    return X_train, X_test, y_train, y_test\n\ndef auto_trainer(X_train, X_test, y_train, y_test):\n    clf = RandomForestClassifier(n_estimators=13, max_depth=5, random_state=42).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    y_pred_train = clf.predict(X_train)\n    #y_pred_proba = clf.predict_proba(X_test[:2, :])\n    clf.score(X_test, y_test)\n   \n    print('Report on test data')\n    print(classification_report(y_test, y_pred))\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    #plt.figure()\n    #sns.heatmap(cf_matrix, annot=True)\n    #$print(cf_matrix)\n    \n    print('Report on train data')\n    print(classification_report(y_train, y_pred_train))\n    cf_matrix = confusion_matrix(y_train, y_pred_train)\n    print(cf_matrix)\n    #plt.figure()\n    #sns.heatmap(cf_matrix, annot=True)\n\n\n#def feature_gen(df_inner, target_name, threshold=0.1): \n#    df = Generator(df_inner[df_inner.columns[:-1]], df_inner[target_name]).multiply(by=2) ## add some chose\n#    corr = Correlations(df[df.columns[:-1]], df[target_name])\n#    cor_dict = corr.corr_feature_analisys()\n#    mi = corr.mutual_info()\n#    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n#    mi_lim_ex = [col for col in mi_lim.keys() if col in df.columns]\n#    df = df.drop(columns=mi_lim_ex, axis=1)\n#    return df\n\n#df_gen = Generator(heart[heart.columns[:-1]], heart['DEATH_EVENT']).multiply(by=2)\ndef feature_gen(df_gen, target_name, threshold=0.1): \n   ## add some chose\n    corr = Correlations(df_gen[df_gen.columns[:-1]], df_gen[target_name])\n    cor_dict = corr.corr_feature_analisys()\n    mi = corr.mutual_info()\n    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n    mi_lim_ex = [col for col in mi_lim.keys() if col in df_gen.columns]\n    df_gen = df_gen.drop(columns=mi_lim_ex, axis=1)\n    return df_gen\n\ndef simple_pipe(df_inner, df_gen, target_name, threshold):\n    ndf = feature_gen(df_gen, target_name, threshold)\n    X_train, X_test, y_train, y_test = train_test_scaller(df_inner, name=target_name)\n    print('W/O manipulations')\n    auto_trainer(X_train, X_test, y_train, y_test)\n    print('With manipulations')\n    X_train, X_test, y_train, y_test = train_test_scaller(ndf, name=target_name)\n    auto_trainer(X_train, X_test, y_train, y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:48:34.652718Z","iopub.execute_input":"2025-12-02T17:48:34.653546Z","iopub.status.idle":"2025-12-02T17:48:34.669593Z","shell.execute_reply.started":"2025-12-02T17:48:34.653506Z","shell.execute_reply":"2025-12-02T17:48:34.668522Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df_gen = Generator(heart[heart.columns[:-1]], heart['DEATH_EVENT']).multiply(by=2)\nsimple_pipe(heart, df_gen, 'DEATH_EVENT', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:48:41.805360Z","iopub.execute_input":"2025-12-02T17:48:41.806236Z","iopub.status.idle":"2025-12-02T17:48:43.252722Z","shell.execute_reply.started":"2025-12-02T17:48:41.806209Z","shell.execute_reply":"2025-12-02T17:48:43.251470Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88        52\n           1       0.74      0.74      0.74        23\n\n    accuracy                           0.84        75\n   macro avg       0.81      0.81      0.81        75\nweighted avg       0.84      0.84      0.84        75\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.99      0.96       151\n           1       0.97      0.85      0.91        73\n\n    accuracy                           0.94       224\n   macro avg       0.95      0.92      0.93       224\nweighted avg       0.94      0.94      0.94       224\n\n[[149   2]\n [ 11  62]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.87      0.90      0.89        52\n           1       0.76      0.70      0.73        23\n\n    accuracy                           0.84        75\n   macro avg       0.82      0.80      0.81        75\nweighted avg       0.84      0.84      0.84        75\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.99      0.96       151\n           1       0.98      0.84      0.90        73\n\n    accuracy                           0.94       224\n   macro avg       0.95      0.91      0.93       224\nweighted avg       0.94      0.94      0.94       224\n\n[[150   1]\n [ 12  61]]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(person[person.columns[:-1]], person['Personality']).multiply(by=2)\nsimple_pipe(person, df_gen, 'Personality', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:51:41.789560Z","iopub.execute_input":"2025-12-02T17:51:41.789878Z","iopub.status.idle":"2025-12-02T17:51:41.846325Z","shell.execute_reply.started":"2025-12-02T17:51:41.789856Z","shell.execute_reply":"2025-12-02T17:51:41.845068Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/4163754374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Personality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Personality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_37/1023634016.py\u001b[0m in \u001b[0;36msimple_pipe\u001b[0;34m(df_inner, df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_scaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W/O manipulations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/1023634016.py\u001b[0m in \u001b[0;36mfeature_gen\u001b[0;34m(df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m    \u001b[0;31m## add some chose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_feature_analisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# exclude columns with have a mu info with target less than 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/3718070297.py\u001b[0m in \u001b[0;36mcorr_feature_analisys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mcor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[1;32m   4573\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4574\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4575\u001b[0;31m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4577\u001b[0m     \u001b[0;31m# If an input is constant, the correlation coefficient is not defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data type %r not inexact\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: data type <class 'numpy.object_'> not inexact"],"ename":"ValueError","evalue":"data type <class 'numpy.object_'> not inexact","output_type":"error"}],"execution_count":33},{"cell_type":"code","source":"person.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:53:14.790659Z","iopub.execute_input":"2025-12-02T17:53:14.791011Z","iopub.status.idle":"2025-12-02T17:53:14.820451Z","shell.execute_reply.started":"2025-12-02T17:53:14.790982Z","shell.execute_reply":"2025-12-02T17:53:14.819539Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2900 entries, 0 to 2899\nData columns (total 8 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Time_spent_Alone           2900 non-null   float64\n 1   Stage_fear                 2900 non-null   object \n 2   Social_event_attendance    2900 non-null   float64\n 3   Going_outside              2900 non-null   float64\n 4   Drained_after_socializing  2900 non-null   object \n 5   Friends_circle_size        2900 non-null   float64\n 6   Post_frequency             2900 non-null   float64\n 7   Personality                2900 non-null   object \ndtypes: float64(5), object(3)\nmemory usage: 181.4+ KB\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"iris = iris.drop(columns='Id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:55:03.202831Z","iopub.execute_input":"2025-12-02T17:55:03.203476Z","iopub.status.idle":"2025-12-02T17:55:03.219140Z","shell.execute_reply.started":"2025-12-02T17:55:03.203451Z","shell.execute_reply":"2025-12-02T17:55:03.217674Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3178392677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['Id'] not found in axis\""],"ename":"KeyError","evalue":"\"['Id'] not found in axis\"","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"iris","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:55:34.788834Z","iopub.execute_input":"2025-12-02T17:55:34.789732Z","iopub.status.idle":"2025-12-02T17:55:34.808347Z","shell.execute_reply.started":"2025-12-02T17:55:34.789695Z","shell.execute_reply":"2025-12-02T17:55:34.807365Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n0              5.1           3.5            1.4           0.2     Iris-setosa\n1              4.9           3.0            1.4           0.2     Iris-setosa\n2              4.7           3.2            1.3           0.2     Iris-setosa\n3              4.6           3.1            1.5           0.2     Iris-setosa\n4              5.0           3.6            1.4           0.2     Iris-setosa\n..             ...           ...            ...           ...             ...\n145            6.7           3.0            5.2           2.3  Iris-virginica\n146            6.3           2.5            5.0           1.9  Iris-virginica\n147            6.5           3.0            5.2           2.0  Iris-virginica\n148            6.2           3.4            5.4           2.3  Iris-virginica\n149            5.9           3.0            5.1           1.8  Iris-virginica\n\n[150 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n# Fit and transform the 'Size' column\niris['Species'] = le.fit_transform(iris['Species'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:59:26.059907Z","iopub.execute_input":"2025-12-02T17:59:26.060292Z","iopub.status.idle":"2025-12-02T17:59:26.065612Z","shell.execute_reply.started":"2025-12-02T17:59:26.060269Z","shell.execute_reply":"2025-12-02T17:59:26.064832Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"df_gen = Generator(iris[iris.columns[:-1]], iris['Species']).multiply(by=2)\nsimple_pipe(iris, df_gen, 'Species', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:59:28.980344Z","iopub.execute_input":"2025-12-02T17:59:28.981098Z","iopub.status.idle":"2025-12-02T17:59:29.113773Z","shell.execute_reply.started":"2025-12-02T17:59:28.981070Z","shell.execute_reply":"2025-12-02T17:59:29.112812Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.93      0.93      0.93        14\n           2       0.92      0.92      0.92        12\n\n    accuracy                           0.95        38\n   macro avg       0.95      0.95      0.95        38\nweighted avg       0.95      0.95      0.95        38\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       1.00      1.00      1.00        36\n           2       1.00      1.00      1.00        38\n\n    accuracy                           1.00       112\n   macro avg       1.00      1.00      1.00       112\nweighted avg       1.00      1.00      1.00       112\n\n[[38  0  0]\n [ 0 36  0]\n [ 0  0 38]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.93      0.93      0.93        14\n           2       0.92      0.92      0.92        12\n\n    accuracy                           0.95        38\n   macro avg       0.95      0.95      0.95        38\nweighted avg       0.95      0.95      0.95        38\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       1.00      1.00      1.00        36\n           2       1.00      1.00      1.00        38\n\n    accuracy                           1.00       112\n   macro avg       1.00      1.00      1.00       112\nweighted avg       1.00      1.00      1.00       112\n\n[[38  0  0]\n [ 0 36  0]\n [ 0  0 38]]\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = feature_gen(iris, 'Personality')\nX_train, X_test, y_train, y_test = train_test_scaller(df, name='Personality')\nauto_trainer(X_train, X_test, y_train, y_test )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = feature_gen(person, 'Personality')\nX_train, X_test, y_train, y_test = train_test_scaller(df, name='Personality')\nauto_trainer(X_train, X_test, y_train, y_test )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:48:53.436715Z","iopub.execute_input":"2025-12-02T17:48:53.437492Z","iopub.status.idle":"2025-12-02T17:48:53.487050Z","shell.execute_reply.started":"2025-12-02T17:48:53.437456Z","shell.execute_reply":"2025-12-02T17:48:53.485775Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/89870887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Personality'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_scaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Personality'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mauto_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/1023634016.py\u001b[0m in \u001b[0;36mfeature_gen\u001b[0;34m(df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m    \u001b[0;31m## add some chose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_feature_analisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# exclude columns with have a mu info with target less than 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/3718070297.py\u001b[0m in \u001b[0;36mcorr_feature_analisys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mcor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[1;32m   4573\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4574\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4575\u001b[0;31m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4577\u001b[0m     \u001b[0;31m# If an input is constant, the correlation coefficient is not defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data type %r not inexact\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: data type <class 'numpy.object_'> not inexact"],"ename":"ValueError","evalue":"data type <class 'numpy.object_'> not inexact","output_type":"error"}],"execution_count":28}]}