{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":420,"sourceType":"datasetVersion","datasetId":19},{"sourceId":2286,"sourceType":"datasetVersion","datasetId":1275},{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310},{"sourceId":256873,"sourceType":"datasetVersion","datasetId":107706},{"sourceId":346098,"sourceType":"datasetVersion","datasetId":149550},{"sourceId":1263738,"sourceType":"datasetVersion","datasetId":727551},{"sourceId":1938459,"sourceType":"datasetVersion","datasetId":1111894},{"sourceId":2650913,"sourceType":"datasetVersion","datasetId":1612087},{"sourceId":2879186,"sourceType":"datasetVersion","datasetId":826163},{"sourceId":3846912,"sourceType":"datasetVersion","datasetId":2289007},{"sourceId":4398600,"sourceType":"datasetVersion","datasetId":2580326},{"sourceId":8175771,"sourceType":"datasetVersion","datasetId":4839515},{"sourceId":11376681,"sourceType":"datasetVersion","datasetId":7122663},{"sourceId":12156348,"sourceType":"datasetVersion","datasetId":7474089}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\nfrom itertools import *\nimport seaborn as sns\nfrom matplotlib.pyplot import figure\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n#from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import mutual_info_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\nfrom sklearn.feature_selection import mutual_info_regression\n\nfrom sklearn.datasets import make_classification, make_regression\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import mutual_info_regression\nfrom scipy import stats\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"id":"VaE8UCJfPk-5","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:09:47.115850Z","iopub.execute_input":"2025-12-04T14:09:47.116211Z","iopub.status.idle":"2025-12-04T14:09:47.122999Z","shell.execute_reply.started":"2025-12-04T14:09:47.116186Z","shell.execute_reply":"2025-12-04T14:09:47.121787Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"## Датасеты и обработка","metadata":{}},{"cell_type":"code","source":"\npd.set_option('future.no_silent_downcasting', True)\nincome = pd.read_csv(\"/kaggle/input/income-classification/income_evaluation.csv\")\nincome = income.replace({' <=50K':0,' >50K':1, ' Male':1, ' Female': 2})\nincome_tr = income[' income']\nincome_sex =  income[' sex']\nincome = income.drop(columns=[' native-country', ' income',  ' sex', ' marital-status'])\nincome['  workclass']= income[' workclass'].replace({' State-gov':'gov', ' Self-emp-not-inc':'Self-emp', ' Federal-gov':'gov',\n       ' Local-gov':'gov', ' Self-emp-inc':'Self-emp', ' Without-pay':'no work',\n       ' Never-worked':'no work'})\n\nincome[' education'] = income[' education'].replace(\n{' Bachelors': 'high', ' HS-grad':'HS', ' 11th':'HS','11th':'HS', ' Masters':'high', ' 9th':'low',\n       ' Some-college':'high', ' Assoc-acdm':'high', ' Assoc-voc':'high', ' 7th-8th':'low',\n       ' Doctorate':'high', ' Prof-school':'high', ' 5th-6th': 'low', ' 10th':'high', ' 1st-4th':'low',\n       ' Preschool':'low', ' 12th':'HS'})\n\n\nincome[' relationship'] = income[' relationship'].replace({' Not-in-family':'Unmarried', ' Husband':'married', ' Wife':'married', ' Own-child':'child', ' Unmarried':'Unmarried',\n       ' Other-relative':'Other'})\nincome = pd.get_dummies(income)\nincome[' sex'] = income_sex\nincome[' income'] = income_tr\n\nmarketing = pd.read_csv(\"/kaggle/input/marketing-campaign-positive-response-prediction/campaign_responses.csv\")\nmarketing = marketing.replace({'No':1, 'Yes':2, 'Male':1, 'Female':2, 'Married':1, 'Single':2})\nmarketing[['gender', \n           'responded', \n           'employed',\n           'marital_status']] = marketing[['gender', \n                                     'responded', \n                                     'employed',\n                                           'marital_status']].astype('float32')\n\nstudent = pd.read_csv(\"/kaggle/input/student-habits-vs-academic-performance/student_habits_performance.csv\")\nstudent = student.replace({'No':1, 'Yes':2, 'Female':1, 'Male':2,'Other':3})\nstudent['diet_quality'] = student['diet_quality'].replace({'Fair':2, 'Good':3, 'Poor':1})\nstudent['parental_education_level'] = student['parental_education_level'].replace({'Master':3, 'High School':1, 'Bachelor':2})\nstudent['internet_quality'] = student['internet_quality'].replace({'Average':2, 'Poor':1, 'Good':3})\nstudent = student.dropna()\nstudent[['gender', 'part_time_job',\n         'diet_quality',\n         'parental_education_level',\n         'internet_quality',\n         'extracurricular_participation']] = student[['gender',\n                                                      'part_time_job', \n                                                      'diet_quality',\n                                                      'parental_education_level',                   \n                                                      'internet_quality',\n                                                      'extracurricular_participation']].astype('float32')\nstudent = student.drop(columns='student_id')\n\nperson = pd.read_csv(\"/kaggle/input/extrovert-vs-introvert-behavior-data/personality_datasert.csv\")\nperson = person.replace({'No':1, 'Yes':2, 'Extrovert':1, 'Introvert':0})\nperson[['Stage_fear','Drained_after_socializing',\n'Personality']] = person[['Stage_fear','Drained_after_socializing',\n'Personality']].astype('int32')\n\nheart = pd.read_csv(\"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\nheart2 = pd.read_csv(\"/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv\", delimiter=';')\nheart2 = heart2.drop(columns='id')\niris = pd.read_csv('/kaggle/input/iris/Iris.csv')\niris = iris.drop(columns='Id')\nle = LabelEncoder()\n# Fit and transform the 'Size' column\niris['Species'] = le.fit_transform(iris['Species'])\n\ncreditfraud = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\nonlinefraud = pd.read_csv('/kaggle/input/online-payment-fraud-detection/onlinefraud.csv')\nonlinefraud = onlinefraud.drop(columns=['nameOrig','nameDest','isFlaggedFraud']) \nonlinefraud['type'] = onlinefraud['type'].replace({'PAYMENT':1,\n                                                  'TRANSFER':2,\n                                                  'CASH_OUT':3, \n                                                  'DEBIT':4, \n                                                  'CASH_IN':4})\nonlinefraud['type'] = onlinefraud['type'].astype('int32')\n\nbankruptcy = pd.read_csv('/kaggle/input/company-bankruptcy-prediction/data.csv')\nb = bankruptcy['Bankrupt?']\nbankruptcy = bankruptcy.drop(columns=['Bankrupt?']) \nbankruptcy['Bankrupt?'] = b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:29:14.896621Z","iopub.execute_input":"2025-12-04T14:29:14.896947Z","iopub.status.idle":"2025-12-04T14:29:34.721174Z","shell.execute_reply.started":"2025-12-04T14:29:14.896924Z","shell.execute_reply":"2025-12-04T14:29:34.720217Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"\nclass Generator():\n\n    def __init__(self, X, y, n_columns = 2):\n       self.X = X\n       self.y = y\n       self.n_columns = n_columns # hiperparametr for generators witch split range of combination\n\n\n    def split_list_by_chunks(self, data, n_columns):\n        for i in range(0, len(data), self.n_columns ):\n            yield data[i:i + self.n_columns]\n\n    def multiply_gen(self, by=2, column_list=None): ## return np with annotation \n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by):\n            combinations_list.append(name_col)\n        \n        combinations_list = self.split_list_by_chunks(combinations_list, self.n_columns )\n        for seq in combinations_list:\n            B = np.empty((len(seq),self.X.shape[0]))\n            list_of_name = []\n            for i, tup in enumerate(seq):\n                A = np.ones(self.X.shape[0])\n                list_of_name.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n                for col in tup:\n                    A *= self.X[col].to_numpy()\n                B[i] = A\n            yield B, list_of_name\n \n\n    def multiply(self, by=2, column_list=None, with_all_data=True):  ## return dataframe \n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by):\n            combinations_list.append(name_col)      \n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            list_of_name.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n            for col in tup:\n                A *= self.X[col]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n        \n\n    def devision_on_last_gen(self, by=3, column_list=None):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, by):\n            combinations_list.append(name_col)\n        combinations_list = self.split_list_by_chunks(combinations_list, self.n_columns )\n\n        for seq in combinations_list:\n            B = np.empty((len(seq),self.X.shape[0]))\n            list_of_name = [] #'multiply and devision - '\n            for i, tup in enumerate(seq):\n                A = np.ones(self.X.shape[0])   \n                list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup[:-1])}, and devision on - {tup[-1]}')\n                for col in tup:\n                    A *= self.X[col].to_numpy()\n                    A = A/(self.X[tup[-1]]*self.X[tup[-1]])\n                B[i] = A\n            yield B, list_of_name\n\n\n         \n\n    def devision_on_last(self, by=3, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, by):\n            combinations_list.append(name_col)\n            \n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup[:-1])}, and devision on - {tup[-1]}')#.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n            for col in tup:\n                A *= self.X[col]\n                A = A/(self.X[tup[-1]]*self.X[tup[-1]])\n                B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n    \n            \n    def devision_in_pairs(self, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, 2):\n            combinations_list.append(name_col)\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            list_of_name.append(f'{str(tup[0])} // {str(tup[1])}')\n            A = X[tup[0]]/X[tup[1]]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n            \n\n\n    def log(self, column_list=None):\n        name_columns = self.X.columns if column_list == None else column_list\n        for col in name_columns:\n            X['log '+ str(col)] = np.log(X[col])    \n        df = X\n        return df\n        \n\n    def exp(self, column_list=None):\n        name_columns = self.X.columns if column_list == None else column_list\n        for col in name_columns:\n            X['exp '+ str(col)] = np.exp(X[col])    \n        df = X\n        return df\n\n    def degree(self, by=2, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, 2):\n            combinations_list.append(name_col)\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            #print(tup[0])\n            list_of_name.append(f'{str(tup[0])} ** {str(tup[1])}')\n            A = X[tup[0]]**X[tup[1]]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([self.X, self.y], axis=1)   \n        else:     \n            return df\n\n    def devision_on_last_2(self, by=3, column_list=None,  with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by-1):\n            combinations_list.append(name_col)\n        A = len(combinations_list)*(self.X.shape[1]-2)\n\n        \n        B = np.empty((A, self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            dev_sub = [el for el in name_columns if el not in tup]\n\n            for col in tup:\n                A *= self.X[col]\n                for dev in dev_sub:\n                    list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup)}, and devision on - {dev}')\n                    A = A/self.X[dev]\n                B[i] = A\n        list_of_name  = list(dict.fromkeys(list_of_name))\n\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n\n    def deltas(self, column_list=None,  with_all_data=True):\n        # use with standart scaler or normalize data only\n        name_columns = self.X.columns if column_list == None else column_list\n        combinations_list = []\n        for name_col in combinations(name_columns, 2):\n            combinations_list.append(name_col)\n        list_of_name = []\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        for i, tup in enumerate(combinations_list): \n            list_of_name.append(f'{str(tup[0])} - {str(tup[1])}')\n            B[i] = self.X[tup[0]]-self.X[tup[1]]\n        df = pd.DataFrame(B.T, columns=list_of_name) #?????\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n        \n    def sums():\n        pass\n  \n        \n\nclass Correlations():\n    def __init__(self, X, y):\n        self.X = X #2d dimentional df\n        self.y = y\n    \n\n    def mutual_info(self, mode='regression'):\n        mi_dict = {}\n        names_col = self.X.columns\n        if mode == 'regression':\n            v = mutual_info_regression(self.X, self.y)\n        else:\n             v = mutual_info_classif(self.X, self.y)\n        \n        for i, j in zip(names_col, v):\n            mi_dict[i]=j\n\n        mi_dict = dict(sorted(mi_dict.items(), key=lambda item: item[1]))\n        return mi_dict\n\n\n    def cramer_with_target(self):\n        corr_val_crammer = {}\n        for col in self.X.columns:\n            confusion_matrix = pd.crosstab(self.X[col], self.y)\n            chi2 = stats.chi2_contingency(confusion_matrix)[0]\n            n = confusion_matrix.sum().sum()\n            r, c = confusion_matrix.shape\n            min_dim = min(r - 1, c - 1)\n            v = np.sqrt(chi2 / (n * min_dim))\n            corr_val_crammer['crammer with target ' + col]= v\n        return corr_val_crammer\n\n\n    def correlation(self, name='pearsonr'):\n        corr_val = {}\n        for col in self.X.columns:\n            if name == 'pearsonr':\n                res = stats.pearsonr(self.X[col], self.y)\n            elif name == 'spearmanr': #Спирмен может быть полезна для нелинейных зависимостей.\n                res = stats.spearmanr(self.X[col], self.y)\n            elif name == 'kendalltau': #Кендалла, также используемой для ранговых данных\n                res = stats.kendalltau(self.X[col], self.y)\n            corr_val[col+' '+name] = res[0]\n        return corr_val\n\n    def heat_map(self):\n        co_mtx = self.X.corr(numeric_only=True)\n        w = co_mtx.shape[0]\n\n        figure(figsize=(w, w), dpi=80)\n        # Plot correlation heatmap\n        sns.heatmap(co_mtx, cmap=\"YlGnBu\", annot=True)\n\n\n\n    def corr_feature_analisys(self):\n        cor_dict = {}\n        names = self.X.columns\n        combinations_list = []\n        for name_col in combinations(names, 2):\n            combinations_list.append(name_col)\n\n        for pairs in combinations_list:\n            stat, _ = stats.pearsonr(self.X[pairs[0]], self.X[pairs[1]])\n            cor_dict[pairs] = stat\n        cor_dict = sorted(cor_dict.items(), key=lambda item: item[1], reverse=True)\n        cor_dict = dict(cor_dict)\n\n        return cor_dict\n\n    def vis_corr_feature_analisys(self):\n        cor_dict = self.corr_feature_analisys()\n        keys = [' '.join(el) for el in cor_dict.keys()]\n        #print(keys[:3], type(keys[2]))\n        #for el in cor_dict.keys():\n         #   cor_dict ', '.join(el)\n        vals = [float(v) for v in cor_dict.values()]#[float(cor_dict.values()) for k in keys]\n        #print(vals, keys)\n        w = len(keys)\n\n        figure(figsize=(w, w), dpi=80)\n        sns.catplot(x=vals, y=keys)\n  \n        \n        \n    def report_cor():\n        #p = correlation()\n        #s = correlation()\n        #k= correlation()\n        pass\n\n    def visulisation():\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:37:47.964444Z","iopub.execute_input":"2025-12-04T13:37:47.964754Z","iopub.status.idle":"2025-12-04T13:37:48.003190Z","shell.execute_reply.started":"2025-12-04T13:37:47.964726Z","shell.execute_reply":"2025-12-04T13:37:48.002205Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Pipe for education and comparison","metadata":{}},{"cell_type":"code","source":"def train_test_scaller(df, name=''):\n    \n    y = df[name]\n    X = df.drop([name], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=99)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    return X_train, X_test, y_train, y_test\n\ndef auto_trainer(X_train, X_test, y_train, y_test):\n    clf = RandomForestClassifier(n_estimators=13, max_depth=5, random_state=42).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    y_pred_train = clf.predict(X_train)\n    #y_pred_proba = clf.predict_proba(X_test[:2, :])\n    clf.score(X_test, y_test)\n   \n    print('Report on test data')\n    print(classification_report(y_test, y_pred))\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    \n    print('Report on train data')\n    print(classification_report(y_train, y_pred_train))\n    cf_matrix = confusion_matrix(y_train, y_pred_train)\n    print(cf_matrix)\n   \ndef feature_gen(df_gen, target_name, threshold=0.1): \n   ## add some chose\n    corr = Correlations(df_gen[df_gen.columns[:-1]], df_gen[target_name])\n    cor_dict = corr.corr_feature_analisys()\n    mi = corr.mutual_info()\n    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n    mi_lim_ex = [col for col in mi_lim.keys() if col in df_gen.columns]\n    df_gen = df_gen.drop(columns=mi_lim_ex, axis=1)\n    return df_gen\n\ndef simple_pipe(df_inner, df_gen, target_name, threshold):\n    ndf = feature_gen(df_gen, target_name, threshold)\n    X_train, X_test, y_train, y_test = train_test_scaller(df_inner, name=target_name)\n    print('W/O manipulations')\n    auto_trainer(X_train, X_test, y_train, y_test)\n    print('With manipulations')\n    X_train, X_test, y_train, y_test = train_test_scaller(ndf, name=target_name)\n    auto_trainer(X_train, X_test, y_train, y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:39:28.904314Z","iopub.execute_input":"2025-12-04T13:39:28.904923Z","iopub.status.idle":"2025-12-04T13:39:28.916698Z","shell.execute_reply.started":"2025-12-04T13:39:28.904894Z","shell.execute_reply":"2025-12-04T13:39:28.915562Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Examples for Classification","metadata":{}},{"cell_type":"code","source":"df_gen = Generator(heart[heart.columns[:-1]], heart['DEATH_EVENT']).multiply(by=2)\nsimple_pipe(heart, df_gen, 'DEATH_EVENT', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:39:34.332909Z","iopub.execute_input":"2025-12-04T13:39:34.333216Z","iopub.status.idle":"2025-12-04T13:39:35.812541Z","shell.execute_reply.started":"2025-12-04T13:39:34.333185Z","shell.execute_reply":"2025-12-04T13:39:35.811718Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88        52\n           1       0.74      0.74      0.74        23\n\n    accuracy                           0.84        75\n   macro avg       0.81      0.81      0.81        75\nweighted avg       0.84      0.84      0.84        75\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.99      0.96       151\n           1       0.97      0.85      0.91        73\n\n    accuracy                           0.94       224\n   macro avg       0.95      0.92      0.93       224\nweighted avg       0.94      0.94      0.94       224\n\n[[149   2]\n [ 11  62]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92        52\n           1       0.89      0.70      0.78        23\n\n    accuracy                           0.88        75\n   macro avg       0.88      0.83      0.85        75\nweighted avg       0.88      0.88      0.88        75\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.96       151\n           1       1.00      0.85      0.92        73\n\n    accuracy                           0.95       224\n   macro avg       0.97      0.92      0.94       224\nweighted avg       0.95      0.95      0.95       224\n\n[[151   0]\n [ 11  62]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_gen = Generator(person[person.columns[:-1]], person['Personality']).multiply(by=2)\nsimple_pipe(person, df_gen, 'Personality', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:45:30.267054Z","iopub.execute_input":"2025-12-04T13:45:30.267367Z","iopub.status.idle":"2025-12-04T13:45:31.045069Z","shell.execute_reply.started":"2025-12-04T13:45:30.267343Z","shell.execute_reply":"2025-12-04T13:45:31.044153Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.92      0.92      0.92       342\n           1       0.93      0.92      0.93       383\n\n    accuracy                           0.92       725\n   macro avg       0.92      0.92      0.92       725\nweighted avg       0.92      0.92      0.92       725\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94      1067\n           1       0.95      0.93      0.94      1108\n\n    accuracy                           0.94      2175\n   macro avg       0.94      0.94      0.94      2175\nweighted avg       0.94      0.94      0.94      2175\n\n[[1015   52]\n [  82 1026]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.92      0.92      0.92       342\n           1       0.93      0.92      0.93       383\n\n    accuracy                           0.92       725\n   macro avg       0.92      0.92      0.92       725\nweighted avg       0.92      0.92      0.92       725\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94      1067\n           1       0.95      0.93      0.94      1108\n\n    accuracy                           0.94      2175\n   macro avg       0.94      0.94      0.94      2175\nweighted avg       0.94      0.94      0.94      2175\n\n[[1015   52]\n [  82 1026]]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"df_gen = Generator(iris[iris.columns[:-1]], iris['Species']).multiply(by=2)\nsimple_pipe(iris, df_gen, 'Species', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:48:05.457625Z","iopub.execute_input":"2025-12-04T13:48:05.457927Z","iopub.status.idle":"2025-12-04T13:48:05.617826Z","shell.execute_reply.started":"2025-12-04T13:48:05.457902Z","shell.execute_reply":"2025-12-04T13:48:05.616930Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.93      0.93      0.93        14\n           2       0.92      0.92      0.92        12\n\n    accuracy                           0.95        38\n   macro avg       0.95      0.95      0.95        38\nweighted avg       0.95      0.95      0.95        38\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       1.00      1.00      1.00        36\n           2       1.00      1.00      1.00        38\n\n    accuracy                           1.00       112\n   macro avg       1.00      1.00      1.00       112\nweighted avg       1.00      1.00      1.00       112\n\n[[38  0  0]\n [ 0 36  0]\n [ 0  0 38]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.93      0.93      0.93        14\n           2       0.92      0.92      0.92        12\n\n    accuracy                           0.95        38\n   macro avg       0.95      0.95      0.95        38\nweighted avg       0.95      0.95      0.95        38\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       1.00      1.00      1.00        36\n           2       1.00      1.00      1.00        38\n\n    accuracy                           1.00       112\n   macro avg       1.00      1.00      1.00       112\nweighted avg       1.00      1.00      1.00       112\n\n[[38  0  0]\n [ 0 36  0]\n [ 0  0 38]]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df_gen = Generator(marketing[marketing.columns[:-1]], marketing['responded']).multiply(by=2)\nsimple_pipe(marketing, df_gen, 'responded', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:07:09.360381Z","iopub.execute_input":"2025-12-04T14:07:09.360695Z","iopub.status.idle":"2025-12-04T14:07:09.740563Z","shell.execute_reply.started":"2025-12-04T14:07:09.360673Z","shell.execute_reply":"2025-12-04T14:07:09.739693Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00         7\n         2.0       1.00      1.00      1.00         7\n\n    accuracy                           1.00        14\n   macro avg       1.00      1.00      1.00        14\nweighted avg       1.00      1.00      1.00        14\n\nReport on train data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00        21\n         2.0       1.00      1.00      1.00        21\n\n    accuracy                           1.00        42\n   macro avg       1.00      1.00      1.00        42\nweighted avg       1.00      1.00      1.00        42\n\n[[21  0]\n [ 0 21]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00         7\n         2.0       1.00      1.00      1.00         7\n\n    accuracy                           1.00        14\n   macro avg       1.00      1.00      1.00        14\nweighted avg       1.00      1.00      1.00        14\n\nReport on train data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00        21\n         2.0       1.00      1.00      1.00        21\n\n    accuracy                           1.00        42\n   macro avg       1.00      1.00      1.00        42\nweighted avg       1.00      1.00      1.00        42\n\n[[21  0]\n [ 0 21]]\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"df_gen = Generator(bankruptcy[bankruptcy.columns[:-1]], bankruptcy['Bankrupt?']).multiply(by=2)\nsimple_pipe(bankruptcy, df_gen, 'Bankrupt?', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:10:53.771744Z","iopub.execute_input":"2025-12-04T14:10:53.772086Z","iopub.status.idle":"2025-12-04T14:23:39.429738Z","shell.execute_reply.started":"2025-12-04T14:10:53.772061Z","shell.execute_reply":"2025-12-04T14:23:39.428579Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_38/2262713051.py:262: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  stat, _ = stats.pearsonr(self.X[pairs[0]], self.X[pairs[1]])\n/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:4638: RuntimeWarning: invalid value encountered in less\n  nconst_y = xp.any(normym < threshold*xp.abs(ymean), axis=axis)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:354: RuntimeWarning: invalid value encountered in less\n  ia = (out < a) | xp.isnan(a)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:361: RuntimeWarning: invalid value encountered in greater\n  ib = (out > b) | xp.isnan(b)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/3034656358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbankruptcy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbankruptcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbankruptcy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bankrupt?'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbankruptcy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bankrupt?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36msimple_pipe\u001b[0;34m(df_inner, df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_scaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W/O manipulations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36mfeature_gen\u001b[0;34m(df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m    \u001b[0;31m## add some chose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_feature_analisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# exclude columns with have a mu info with target less than 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/2262713051.py\u001b[0m in \u001b[0;36mcorr_feature_analisys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mcor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[1;32m   4636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4637\u001b[0m     \u001b[0mnconst_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormxm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4638\u001b[0;31m     \u001b[0mnconst_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormym\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4639\u001b[0m     \u001b[0mnconst_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnconst_x\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnconst_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnconst_xy\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mconst_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_any_dispatcher\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m def _any_dispatcher(a, axis=None, out=None, keepdims=None, *,\n\u001b[0m\u001b[1;32m   2318\u001b[0m                     where=np._NoValue):\n\u001b[1;32m   2319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":61},{"cell_type":"code","source":"df_gen = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).multiply(by=2)\nsimple_pipe(heart2, df_gen, 'cardio', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:30:41.694348Z","iopub.execute_input":"2025-12-04T14:30:41.694670Z","iopub.status.idle":"2025-12-04T14:31:23.109821Z","shell.execute_reply.started":"2025-12-04T14:30:41.694621Z","shell.execute_reply":"2025-12-04T14:31:23.108833Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75      8705\n           1       0.77      0.67      0.72      8795\n\n    accuracy                           0.73     17500\n   macro avg       0.74      0.73      0.73     17500\nweighted avg       0.74      0.73      0.73     17500\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.70      0.80      0.75     26316\n           1       0.76      0.66      0.71     26184\n\n    accuracy                           0.73     52500\n   macro avg       0.73      0.73      0.73     52500\nweighted avg       0.73      0.73      0.73     52500\n\n[[20924  5392]\n [ 8844 17340]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75      8705\n           1       0.77      0.68      0.72      8795\n\n    accuracy                           0.73     17500\n   macro avg       0.74      0.73      0.73     17500\nweighted avg       0.74      0.73      0.73     17500\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.70      0.79      0.74     26316\n           1       0.76      0.66      0.71     26184\n\n    accuracy                           0.73     52500\n   macro avg       0.73      0.73      0.73     52500\nweighted avg       0.73      0.73      0.73     52500\n\n[[20824  5492]\n [ 8800 17384]]\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"df_gen = Generator(onlinefraud[onlinefraud.columns[:-1]], onlinefraud['isFraud']).multiply(by=2)\nsimple_pipe(onlinefraud, df_gen, 'isFraud', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:32:18.070217Z","iopub.execute_input":"2025-12-04T14:32:18.070530Z","execution_failed":"2025-12-05T05:57:01.261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(creditfraud[onlinefraud.columns[:-1]], onlinefraud['Class']).multiply(by=2)\nsimple_pipe(onlinefraud, df_gen, 'Class', 0.1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-05T05:57:01.271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(bankruptcy[bankruptcy.columns[:-1]], bankruptcy['Bankrupt?']).multiply(by=2)\nsimple_pipe(bankruptcy, df_gen, 'Bankrupt?', 0.1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_test_scaller(df, name=''):\n    \n    y = df[name]\n    X = df.drop([name], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=99)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    return X_train, X_test, y_train, y_test\n\ndef auto_trainer(X_train, X_test, y_train, y_test):\n    clf = RandomForestRegressor(n_estimators=13, max_depth=5, random_state=42).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    y_pred_train = clf.predict(X_train)\n    #y_pred_proba = clf.predict_proba(X_test[:2, :])\n    clf.score(X_test, y_test)\n   \n    print('Report on test data')\n    print(classification_report(y_test, y_pred))\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    #plt.figure()\n    #sns.heatmap(cf_matrix, annot=True)\n    #$print(cf_matrix)\n    \n    print('Report on train data')\n    print(classification_report(y_train, y_pred_train))\n    cf_matrix = confusion_matrix(y_train, y_pred_train)\n    print(cf_matrix)\n    #plt.figure()\n    #sns.heatmap(cf_matrix, annot=True)\n\n\n#def feature_gen(df_inner, target_name, threshold=0.1): \n#    df = Generator(df_inner[df_inner.columns[:-1]], df_inner[target_name]).multiply(by=2) ## add some chose\n#    corr = Correlations(df[df.columns[:-1]], df[target_name])\n#    cor_dict = corr.corr_feature_analisys()\n#    mi = corr.mutual_info()\n#    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n#    mi_lim_ex = [col for col in mi_lim.keys() if col in df.columns]\n#    df = df.drop(columns=mi_lim_ex, axis=1)\n#    return df\n\n#df_gen = Generator(heart[heart.columns[:-1]], heart['DEATH_EVENT']).multiply(by=2)\ndef feature_gen(df_gen, target_name, threshold=0.1): \n   ## add some chose\n    corr = Correlations(df_gen[df_gen.columns[:-1]], df_gen[target_name])\n    cor_dict = corr.corr_feature_analisys()\n    mi = corr.mutual_info()\n    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n    mi_lim_ex = [col for col in mi_lim.keys() if col in df_gen.columns]\n    df_gen = df_gen.drop(columns=mi_lim_ex, axis=1)\n    return df_gen\n\ndef simple_pipe(df_inner, df_gen, target_name, threshold):\n    ndf = feature_gen(df_gen, target_name, threshold)\n    X_train, X_test, y_train, y_test = train_test_scaller(df_inner, name=target_name)\n    print('W/O manipulations')\n    auto_trainer(X_train, X_test, y_train, y_test)\n    print('With manipulations')\n    X_train, X_test, y_train, y_test = train_test_scaller(ndf, name=target_name)\n    auto_trainer(X_train, X_test, y_train, y_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(student[student.columns[:-1]], student['exam_score']).multiply(by=2)\nsimple_pipe(student, df_gen, 'exam_score', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:59:33.931988Z","iopub.execute_input":"2025-12-04T13:59:33.932232Z","iopub.status.idle":"2025-12-04T13:59:36.355496Z","shell.execute_reply.started":"2025-12-04T13:59:33.932210Z","shell.execute_reply":"2025-12-04T13:59:36.354241Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:4637: RuntimeWarning: invalid value encountered in less\n  nconst_x = xp.any(normxm < threshold*xp.abs(xmean), axis=axis)\n/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:4638: RuntimeWarning: invalid value encountered in less\n  nconst_y = xp.any(normym < threshold*xp.abs(ymean), axis=axis)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:354: RuntimeWarning: invalid value encountered in less\n  ia = (out < a) | xp.isnan(a)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:361: RuntimeWarning: invalid value encountered in greater\n  ib = (out > b) | xp.isnan(b)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/4221916904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exam_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exam_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36msimple_pipe\u001b[0;34m(df_inner, df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_scaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W/O manipulations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36mfeature_gen\u001b[0;34m(df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_feature_analisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# exclude columns with have a mu info with target less than 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmi_lim_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi_lim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/2262713051.py\u001b[0m in \u001b[0;36mmutual_info\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mnames_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'regression'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m              \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    386\u001b[0m            \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbl\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPeredachi\u001b[0m \u001b[0mInf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1987\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_estimate_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    253\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN."],"ename":"ValueError","evalue":"Input X contains NaN.","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"student['gender'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:57:00.855761Z","iopub.execute_input":"2025-12-04T13:57:00.856487Z","iopub.status.idle":"2025-12-04T13:57:00.862211Z","shell.execute_reply.started":"2025-12-04T13:57:00.856453Z","shell.execute_reply":"2025-12-04T13:57:00.861227Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"array([1, 2, 'Other'], dtype=object)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"df = feature_gen(iris, 'Personality')\nX_train, X_test, y_train, y_test = train_test_scaller(df, name='Personality')\nauto_trainer(X_train, X_test, y_train, y_test )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}