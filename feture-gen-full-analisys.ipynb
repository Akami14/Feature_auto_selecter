{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":420,"sourceType":"datasetVersion","datasetId":19},{"sourceId":2286,"sourceType":"datasetVersion","datasetId":1275},{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310},{"sourceId":256873,"sourceType":"datasetVersion","datasetId":107706},{"sourceId":346098,"sourceType":"datasetVersion","datasetId":149550},{"sourceId":1263738,"sourceType":"datasetVersion","datasetId":727551},{"sourceId":1938459,"sourceType":"datasetVersion","datasetId":1111894},{"sourceId":2650913,"sourceType":"datasetVersion","datasetId":1612087},{"sourceId":2879186,"sourceType":"datasetVersion","datasetId":826163},{"sourceId":3846912,"sourceType":"datasetVersion","datasetId":2289007},{"sourceId":4398600,"sourceType":"datasetVersion","datasetId":2580326},{"sourceId":8175771,"sourceType":"datasetVersion","datasetId":4839515},{"sourceId":11376681,"sourceType":"datasetVersion","datasetId":7122663},{"sourceId":12156348,"sourceType":"datasetVersion","datasetId":7474089}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\nfrom itertools import *\nimport seaborn as sns\nfrom matplotlib.pyplot import figure\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n#from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import mutual_info_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\nfrom sklearn.feature_selection import mutual_info_regression\n\nfrom sklearn.datasets import make_classification, make_regression\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import mutual_info_regression\nfrom scipy import stats\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"id":"VaE8UCJfPk-5","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T10:41:35.218593Z","iopub.execute_input":"2025-12-13T10:41:35.218888Z","iopub.status.idle":"2025-12-13T10:41:37.264073Z","shell.execute_reply.started":"2025-12-13T10:41:35.218865Z","shell.execute_reply":"2025-12-13T10:41:37.262890Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Датасеты и обработка","metadata":{}},{"cell_type":"code","source":"\npd.set_option('future.no_silent_downcasting', True)\n\nstudent = pd.read_csv(\"/kaggle/input/student-habits-vs-academic-performance/student_habits_performance.csv\")\nstudent = student.replace({'No':1, 'Yes':2, 'Female':1, 'Male':2,'Other':3})\nstudent['diet_quality'] = student['diet_quality'].replace({'Fair':2, 'Good':3, 'Poor':1})\nstudent['parental_education_level'] = student['parental_education_level'].replace({'Master':3, 'High School':1, 'Bachelor':2})\nstudent['internet_quality'] = student['internet_quality'].replace({'Average':2, 'Poor':1, 'Good':3})\nstudent = student.dropna()\nstudent[['gender', 'part_time_job',\n         'diet_quality',\n         'parental_education_level',\n         'internet_quality',\n         'extracurricular_participation']] = student[['gender',\n                                                      'part_time_job', \n                                                      'diet_quality',\n                                                      'parental_education_level',                   \n                                                      'internet_quality',\n                                                      'extracurricular_participation']].astype('float32')\nstudent = student.drop(columns='student_id')\n\nperson = pd.read_csv(\"/kaggle/input/extrovert-vs-introvert-behavior-data/personality_datasert.csv\")\nperson = person.replace({'No':1, 'Yes':2, 'Extrovert':1, 'Introvert':0})\nperson[['Stage_fear','Drained_after_socializing',\n'Personality']] = person[['Stage_fear','Drained_after_socializing',\n'Personality']].astype('int32')\n\n\nheart2 = pd.read_csv(\"/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv\", delimiter=';')\nheart2 = heart2.drop(columns='id')\nheart2['smoke'] = heart2['smoke'].replace({0:1, 1:2})\nheart2 ['alco'] = heart2 ['alco'] .replace({0:1, 1:2})\nheart2['active'] = heart2['active'].replace({0:1, 1:2})\n\n#heart2 = heart2.replace({'Master':3, 'High School':1, 'Bachelor':2\n                        \niris = pd.read_csv('/kaggle/input/iris/Iris.csv')\niris = iris.drop(columns='Id')\nle = LabelEncoder()\n# Fit and transform the 'Size' column\niris['Species'] = le.fit_transform(iris['Species'])\n\ncreditfraud = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\nonlinefraud = pd.read_csv('/kaggle/input/online-payment-fraud-detection/onlinefraud.csv')\nonlinefraud = onlinefraud.drop(columns=['nameOrig','nameDest','isFlaggedFraud']) \nonlinefraud['type'] = onlinefraud['type'].replace({'PAYMENT':1,\n                                                  'TRANSFER':2,\n                                                  'CASH_OUT':3, \n                                                  'DEBIT':4, \n                                                  'CASH_IN':4})\nonlinefraud['type'] = onlinefraud['type'].astype('int32')\n\nbankruptcy = pd.read_csv('/kaggle/input/company-bankruptcy-prediction/data.csv')\nb = bankruptcy['Bankrupt?']\nbankruptcy = bankruptcy.drop(columns=['Bankrupt?']) \nbankruptcy['Bankrupt?'] = b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T10:45:14.210203Z","iopub.execute_input":"2025-12-13T10:45:14.210510Z","iopub.status.idle":"2025-12-13T10:45:33.938477Z","shell.execute_reply.started":"2025-12-13T10:45:14.210491Z","shell.execute_reply":"2025-12-13T10:45:33.937471Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\nclass Generator():\n\n    def __init__(self, X, y, n_columns = 2):\n       self.X = X\n       self.y = y\n       self.n_columns = n_columns # hiperparametr for generators witch split range of combination\n\n\n    def split_list_by_chunks(self, data, n_columns):\n        for i in range(0, len(data), self.n_columns ):\n            yield data[i:i + self.n_columns]\n\n    def multiply_gen(self, by=2, column_list=None): ## return np with annotation \n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by):\n            combinations_list.append(name_col)\n        \n        combinations_list = self.split_list_by_chunks(combinations_list, self.n_columns )\n        for seq in combinations_list:\n            B = np.empty((len(seq),self.X.shape[0]))\n            list_of_name = []\n            for i, tup in enumerate(seq):\n                A = np.ones(self.X.shape[0])\n                list_of_name.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n                for col in tup:\n                    A *= self.X[col].to_numpy()\n                B[i] = A\n            yield B, list_of_name\n \n\n    def multiply(self, by=2, column_list=None, with_all_data=True):  ## return dataframe \n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by):\n            combinations_list.append(name_col)      \n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            list_of_name.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n            for col in tup:\n                A *= self.X[col]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n        \n\n    def devision_on_last_gen(self, by=3, column_list=None):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, by):\n            combinations_list.append(name_col)\n        combinations_list = self.split_list_by_chunks(combinations_list, self.n_columns )\n\n        for seq in combinations_list:\n            B = np.empty((len(seq),self.X.shape[0]))\n            list_of_name = [] #'multiply and devision - '\n            for i, tup in enumerate(seq):\n                A = np.ones(self.X.shape[0])   \n                list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup[:-1])}, and devision on - {tup[-1]}')\n                for col in tup:\n                    A *= self.X[col].to_numpy()\n                    A = A/(self.X[tup[-1]]*self.X[tup[-1]])\n                B[i] = A\n            yield B, list_of_name\n\n\n         \n\n    def devision_on_last(self, by=3, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, by):\n            combinations_list.append(name_col)\n            \n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup[:-1])}, and devision on - {tup[-1]}')#.append(f'multiply of - {\" \".join(str(item) for item in tup)}')\n            for col in tup:\n                A *= self.X[col]\n                A = A/(self.X[tup[-1]]*self.X[tup[-1]])\n                B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n    \n            \n    def devision_in_pairs(self, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, 2):\n            combinations_list.append(name_col)\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            list_of_name.append(f'{str(tup[0])} // {str(tup[1])}')\n            A = X[tup[0]]/X[tup[1]]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n            \n\n\n    def log(self, column_list=None):\n        name_columns = self.X.columns if column_list == None else column_list\n        for col in name_columns:\n            self.X['log '+ str(col)] = np.log(self.X[col])    \n        df = pd.concat([self.X, self.y], axis=1)  \n        return df\n        \n\n    def exp(self, column_list=None):\n        name_columns = self.X.columns if column_list == None else column_list\n        #B = np.empty((len(combinations_list),self.X.shape[0]))\n        for col in name_columns:\n            self.X['exp '+ str(col)] = np.exp.self.X[col]    \n        df = pd.concat([self.X, self.y], axis=1)   \n        return df\n\n    def degree(self, by=2, column_list=None, with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in permutations(name_columns, 2):\n            combinations_list.append(name_col)\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            #print(tup[0])\n            list_of_name.append(f'{str(tup[0])} ** {str(tup[1])}')\n            A = X[tup[0]]**X[tup[1]]\n            B[i] = A\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([self.X, self.y], axis=1)   \n        else:     \n            return df\n\n    def devision_on_last_2(self, by=3, column_list=None,  with_all_data=True):\n        combinations_list = []\n        name_columns = self.X.columns if column_list == None else column_list\n        for name_col in combinations(name_columns, by-1):\n            combinations_list.append(name_col)\n        A = len(combinations_list)*(self.X.shape[1]-2)\n\n        \n        B = np.empty((A, self.X.shape[0]))\n        list_of_name = []\n        for i, tup in enumerate(combinations_list):\n            A = np.ones(self.X.shape[0])\n            dev_sub = [el for el in name_columns if el not in tup]\n\n            for col in tup:\n                A *= self.X[col]\n                for dev in dev_sub:\n                    list_of_name.append(f'multiply on - {\" \".join(str(item) for item in tup)}, and devision on - {dev}')\n                    A = A/self.X[dev]\n                B[i] = A\n        list_of_name  = list(dict.fromkeys(list_of_name))\n\n        df = pd.DataFrame(B.T, columns=list_of_name)\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n\n    def deltas(self, column_list=None,  with_all_data=True):\n        # use with standart scaler or normalize data only\n        name_columns = self.X.columns if column_list == None else column_list\n        combinations_list = []\n        for name_col in combinations(name_columns, 2):\n            combinations_list.append(name_col)\n        list_of_name = []\n        B = np.empty((len(combinations_list),self.X.shape[0]))\n        for i, tup in enumerate(combinations_list): \n            list_of_name.append(f'{str(tup[0])} - {str(tup[1])}')\n            B[i] = self.X[tup[0]]-self.X[tup[1]]\n        df = pd.DataFrame(B.T, columns=list_of_name) #?????\n        if with_all_data:\n            return pd.concat([df, self.X, self.y], axis=1)   \n        else:     \n            return df\n        \n    def sums():\n        pass\n  \n        \n\nclass Correlations():\n    def __init__(self, X, y):\n        self.X = X #2d dimentional df\n        self.y = y\n    \n\n    def mutual_info(self, mode='regression'):\n        mi_dict = {}\n        names_col = self.X.columns\n        if mode == 'regression':\n            v = mutual_info_regression(self.X, self.y)\n        elif mode == 'classification':\n            v = mutual_info_classif(self.X, self.y)\n        else:\n            print(\"mode was no chosen\")\n        for i, j in zip(names_col, v):\n            mi_dict[i]=j\n    \n        mi_dict = dict(sorted(mi_dict.items(), key=lambda item: item[1], reverse=True))\n        mi_df = pd.Series(mi_dict, name='mu_info')\n        #    mi_dict = dict(sorted(mi_dict.items(), key=lambda item: item[1], reverse=True))\n        return mi_df\n\n\n    def cramer_with_target(self):\n        corr_val_crammer = {}\n        for col in self.X.columns:\n            confusion_matrix = pd.crosstab(self.X[col], self.y)\n            chi2 = stats.chi2_contingency(confusion_matrix)[0]\n            n = confusion_matrix.sum().sum()\n            r, c = confusion_matrix.shape\n            min_dim = min(r - 1, c - 1)\n            v = np.sqrt(chi2 / (n * min_dim))\n            corr_val_crammer['crammer with target ' + col]= v\n            corr_val_df_crammer = pd.Series(corr_val_crammer, name='corr_val_crammer')\n        return corr_val_df_crammer\n\n\n    def correlation(self, name='pearsonr'):\n        corr_val = {}\n        for col in self.X.columns:\n            if name == 'pearsonr':\n                res = stats.pearsonr(self.X[col], self.y)\n            elif name == 'spearmanr': #Спирмен может быть полезна для нелинейных зависимостей.\n                res = stats.spearmanr(self.X[col], self.y)\n            elif name == 'kendalltau': #Кендалла, также используемой для ранговых данных\n                res = stats.kendalltau(self.X[col], self.y)\n            corr_val[col] = res[0]\n        corr_val = sorted(corr_val.items(), key=lambda item: item[1], reverse=True)\n        corr_val = dict(corr_val)\n        corr_val_df = pd.Series(corr_val, name=name)\n        return corr_val_df\n\n    def heat_map(self):\n        co_mtx = self.X.corr(numeric_only=True)\n        w = co_mtx.shape[0]\n\n        figure(figsize=(w, w), dpi=80)\n        # Plot correlation heatmap\n        sns.heatmap(co_mtx, cmap=\"YlGnBu\", annot=True)\n\n\n\n    def corr_feature_analisys(self):\n        cor_dict = {}\n        names = self.X.columns\n        combinations_list = []\n        for name_col in combinations(names, 2):\n            combinations_list.append(name_col)\n\n        for pairs in combinations_list:\n            stat, _ = stats.pearsonr(self.X[pairs[0]], self.X[pairs[1]])\n            cor_dict[pairs] = stat\n        cor_dict = sorted(cor_dict.items(), key=lambda item: item[1], reverse=True)\n        cor_dict = dict(cor_dict)\n\n        return cor_dict\n\n    def vis_corr_feature_analisys(self):\n        cor_dict = self.corr_feature_analisys()\n        keys = [' '.join(el) for el in cor_dict.keys()]\n        vals = [float(v) for v in cor_dict.values()]#[float(cor_dict.values()) for k in keys]\n        w = len(keys)\n        figure(figsize=(w, w), dpi=80)\n        sns.catplot(x=vals, y=keys)\n\n    def full_corr(self, mode='classification'):\n        sf1 = self.correlation(name='pearsonr')\n        #sf1['spearmanr'] = self.correlation(name='spearmanr')[]\n        sf2 = self.correlation(name='spearmanr')\n        sf3 = self.correlation(name='kendalltau')\n        sf4 = self.mutual_info(mode=mode)\n        df1 =  pd.merge(sf1, sf2, how='inner', left_index=True, right_index=True)\n        df2 = pd.merge(sf3, sf4, how='inner', left_index=True, right_index=True)\n        df3 = pd.merge(df1, df2, how='inner', left_index=True, right_index=True)\n        return df3\n        \n        \n  \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:08:52.846119Z","iopub.execute_input":"2025-12-13T11:08:52.846641Z","iopub.status.idle":"2025-12-13T11:08:52.885854Z","shell.execute_reply.started":"2025-12-13T11:08:52.846614Z","shell.execute_reply":"2025-12-13T11:08:52.885042Z"},"_kg_hide-input":true},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"## Corr Analysis","metadata":{}},{"cell_type":"markdown","source":"## Multiplay in pairs","metadata":{}},{"cell_type":"code","source":"df_gen = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).multiply(by=2)\ncorr = Correlations(df_gen[df_gen.columns[:-1]], df_gen['cardio'])\ncor_df =  corr.full_corr(mode='classification')\ncor_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T10:49:07.506372Z","iopub.execute_input":"2025-12-13T10:49:07.507321Z","iopub.status.idle":"2025-12-13T10:49:33.649534Z","shell.execute_reply.started":"2025-12-13T10:49:07.507282Z","shell.execute_reply":"2025-12-13T10:49:33.648791Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                  pearsonr  spearmanr  kendalltau   mu_info\nmultiply of - age weight          0.270089   0.277935    0.226935  0.039370\nmultiply of - age cholesterol     0.254517   0.297757    0.243132  0.054637\nmultiply of - weight cholesterol  0.250368   0.258768    0.212919  0.036105\nage                               0.238159   0.234429    0.191428  0.033344\nmultiply of - age height          0.222389   0.219603    0.179307  0.025331\n...                                    ...        ...         ...       ...\nmultiply of - smoke alco         -0.016406  -0.010538   -0.010433  0.005223\nmultiply of - alco active        -0.030120  -0.034721   -0.034109  0.006330\nmultiply of - smoke active       -0.035532  -0.037577   -0.036644  0.008135\nactive                           -0.035653  -0.035653   -0.035653  0.005710\nmultiply of - height active      -0.037438  -0.034342   -0.028426  0.003052\n\n[66 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pearsonr</th>\n      <th>spearmanr</th>\n      <th>kendalltau</th>\n      <th>mu_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>multiply of - age weight</th>\n      <td>0.270089</td>\n      <td>0.277935</td>\n      <td>0.226935</td>\n      <td>0.039370</td>\n    </tr>\n    <tr>\n      <th>multiply of - age cholesterol</th>\n      <td>0.254517</td>\n      <td>0.297757</td>\n      <td>0.243132</td>\n      <td>0.054637</td>\n    </tr>\n    <tr>\n      <th>multiply of - weight cholesterol</th>\n      <td>0.250368</td>\n      <td>0.258768</td>\n      <td>0.212919</td>\n      <td>0.036105</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.238159</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.033344</td>\n    </tr>\n    <tr>\n      <th>multiply of - age height</th>\n      <td>0.222389</td>\n      <td>0.219603</td>\n      <td>0.179307</td>\n      <td>0.025331</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>multiply of - smoke alco</th>\n      <td>-0.016406</td>\n      <td>-0.010538</td>\n      <td>-0.010433</td>\n      <td>0.005223</td>\n    </tr>\n    <tr>\n      <th>multiply of - alco active</th>\n      <td>-0.030120</td>\n      <td>-0.034721</td>\n      <td>-0.034109</td>\n      <td>0.006330</td>\n    </tr>\n    <tr>\n      <th>multiply of - smoke active</th>\n      <td>-0.035532</td>\n      <td>-0.037577</td>\n      <td>-0.036644</td>\n      <td>0.008135</td>\n    </tr>\n    <tr>\n      <th>active</th>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>0.005710</td>\n    </tr>\n    <tr>\n      <th>multiply of - height active</th>\n      <td>-0.037438</td>\n      <td>-0.034342</td>\n      <td>-0.028426</td>\n      <td>0.003052</td>\n    </tr>\n  </tbody>\n</table>\n<p>66 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## Myltiply in 5","metadata":{}},{"cell_type":"code","source":"df_gen2_2 = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).multiply(by=5)\ncorr = Correlations(df_gen2_2[df_gen2_2.columns[:-1]], df_gen2_2['cardio'])\ncor_df2 =  corr.full_corr(mode='classification')\ncor_df2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T10:52:42.821953Z","iopub.execute_input":"2025-12-13T10:52:42.822355Z","iopub.status.idle":"2025-12-13T10:55:53.550242Z","shell.execute_reply.started":"2025-12-13T10:52:42.822330Z","shell.execute_reply":"2025-12-13T10:55:53.549406Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                                    pearsonr  spearmanr  \\\nmultiply of - age height weight cholesterol active  0.242811   0.246223   \nmultiply of - age height weight cholesterol alco    0.242382   0.290936   \nage                                                 0.238159   0.234429   \nmultiply of - age height weight cholesterol smoke   0.235253   0.278915   \nmultiply of - age weight cholesterol alco active    0.221943   0.239168   \n...                                                      ...        ...   \nalco                                               -0.007330  -0.007330   \nheight                                             -0.010821  -0.012383   \nsmoke                                              -0.015486  -0.015486   \nmultiply of - gender height smoke alco active      -0.020567  -0.020373   \nactive                                             -0.035653  -0.035653   \n\n                                                    kendalltau   mu_info  \nmultiply of - age height weight cholesterol active    0.201042  0.035990  \nmultiply of - age height weight cholesterol alco      0.237550  0.047276  \nage                                                   0.191428  0.033929  \nmultiply of - age height weight cholesterol smoke     0.227735  0.044058  \nmultiply of - age weight cholesterol alco active      0.195281  0.037115  \n...                                                        ...       ...  \nalco                                                 -0.007330  0.005993  \nheight                                               -0.010315  0.000000  \nsmoke                                                -0.015486  0.006609  \nmultiply of - gender height smoke alco active        -0.016781  0.000544  \nactive                                               -0.035653  0.010156  \n\n[473 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pearsonr</th>\n      <th>spearmanr</th>\n      <th>kendalltau</th>\n      <th>mu_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>multiply of - age height weight cholesterol active</th>\n      <td>0.242811</td>\n      <td>0.246223</td>\n      <td>0.201042</td>\n      <td>0.035990</td>\n    </tr>\n    <tr>\n      <th>multiply of - age height weight cholesterol alco</th>\n      <td>0.242382</td>\n      <td>0.290936</td>\n      <td>0.237550</td>\n      <td>0.047276</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.238159</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.033929</td>\n    </tr>\n    <tr>\n      <th>multiply of - age height weight cholesterol smoke</th>\n      <td>0.235253</td>\n      <td>0.278915</td>\n      <td>0.227735</td>\n      <td>0.044058</td>\n    </tr>\n    <tr>\n      <th>multiply of - age weight cholesterol alco active</th>\n      <td>0.221943</td>\n      <td>0.239168</td>\n      <td>0.195281</td>\n      <td>0.037115</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>alco</th>\n      <td>-0.007330</td>\n      <td>-0.007330</td>\n      <td>-0.007330</td>\n      <td>0.005993</td>\n    </tr>\n    <tr>\n      <th>height</th>\n      <td>-0.010821</td>\n      <td>-0.012383</td>\n      <td>-0.010315</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>smoke</th>\n      <td>-0.015486</td>\n      <td>-0.015486</td>\n      <td>-0.015486</td>\n      <td>0.006609</td>\n    </tr>\n    <tr>\n      <th>multiply of - gender height smoke alco active</th>\n      <td>-0.020567</td>\n      <td>-0.020373</td>\n      <td>-0.016781</td>\n      <td>0.000544</td>\n    </tr>\n    <tr>\n      <th>active</th>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>0.010156</td>\n    </tr>\n  </tbody>\n</table>\n<p>473 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Myltiply in 3","metadata":{}},{"cell_type":"code","source":"df_gen2 = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).multiply(by=3)\ncorr = Correlations(df_gen2[df_gen2.columns[:-1]], df_gen2_2['cardio'])\ncor_df2_2 =  corr.full_corr(mode='classification')\ncor_df2_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T10:56:07.731462Z","iopub.execute_input":"2025-12-13T10:56:07.731836Z","iopub.status.idle":"2025-12-13T10:57:17.233783Z","shell.execute_reply.started":"2025-12-13T10:56:07.731781Z","shell.execute_reply":"2025-12-13T10:57:17.232804Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                         pearsonr  spearmanr  kendalltau  \\\nmultiply of - age weight cholesterol     0.275596   0.319453    0.260835   \nmultiply of - age height cholesterol     0.253729   0.290916    0.237534   \nmultiply of - age height weight          0.251413   0.258015    0.210670   \nmultiply of - height weight cholesterol  0.246332   0.248168    0.202742   \nage                                      0.238159   0.234429    0.191428   \n...                                           ...        ...         ...   \nmultiply of - gender smoke active       -0.019528  -0.016451   -0.015527   \nmultiply of - smoke alco active         -0.030608  -0.033143   -0.032034   \nmultiply of - height alco active        -0.031021  -0.033470   -0.027675   \nmultiply of - height smoke active       -0.035604  -0.035091   -0.029000   \nactive                                  -0.035653  -0.035653   -0.035653   \n\n                                          mu_info  \nmultiply of - age weight cholesterol     0.055484  \nmultiply of - age height cholesterol     0.044859  \nmultiply of - age height weight          0.036248  \nmultiply of - height weight cholesterol  0.038194  \nage                                      0.031555  \n...                                           ...  \nmultiply of - gender smoke active        0.000764  \nmultiply of - smoke alco active          0.009537  \nmultiply of - height alco active         0.001581  \nmultiply of - height smoke active        0.000022  \nactive                                   0.006564  \n\n[176 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pearsonr</th>\n      <th>spearmanr</th>\n      <th>kendalltau</th>\n      <th>mu_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>multiply of - age weight cholesterol</th>\n      <td>0.275596</td>\n      <td>0.319453</td>\n      <td>0.260835</td>\n      <td>0.055484</td>\n    </tr>\n    <tr>\n      <th>multiply of - age height cholesterol</th>\n      <td>0.253729</td>\n      <td>0.290916</td>\n      <td>0.237534</td>\n      <td>0.044859</td>\n    </tr>\n    <tr>\n      <th>multiply of - age height weight</th>\n      <td>0.251413</td>\n      <td>0.258015</td>\n      <td>0.210670</td>\n      <td>0.036248</td>\n    </tr>\n    <tr>\n      <th>multiply of - height weight cholesterol</th>\n      <td>0.246332</td>\n      <td>0.248168</td>\n      <td>0.202742</td>\n      <td>0.038194</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.238159</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.031555</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>multiply of - gender smoke active</th>\n      <td>-0.019528</td>\n      <td>-0.016451</td>\n      <td>-0.015527</td>\n      <td>0.000764</td>\n    </tr>\n    <tr>\n      <th>multiply of - smoke alco active</th>\n      <td>-0.030608</td>\n      <td>-0.033143</td>\n      <td>-0.032034</td>\n      <td>0.009537</td>\n    </tr>\n    <tr>\n      <th>multiply of - height alco active</th>\n      <td>-0.031021</td>\n      <td>-0.033470</td>\n      <td>-0.027675</td>\n      <td>0.001581</td>\n    </tr>\n    <tr>\n      <th>multiply of - height smoke active</th>\n      <td>-0.035604</td>\n      <td>-0.035091</td>\n      <td>-0.029000</td>\n      <td>0.000022</td>\n    </tr>\n    <tr>\n      <th>active</th>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>0.006564</td>\n    </tr>\n  </tbody>\n</table>\n<p>176 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Deltas","metadata":{}},{"cell_type":"code","source":"df_gen3 = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).deltas()\ncorr = Correlations(df_gen3[df_gen3.columns[:-1]], df_gen3['cardio'])\ncor_df3 =  corr.full_corr(mode='classification')\ncor_df3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T10:57:58.460561Z","iopub.execute_input":"2025-12-13T10:57:58.460897Z","iopub.status.idle":"2025-12-13T10:58:24.543485Z","shell.execute_reply.started":"2025-12-13T10:57:58.460878Z","shell.execute_reply":"2025-12-13T10:58:24.542554Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                      pearsonr  spearmanr  kendalltau   mu_info\nage - active          0.238165   0.234437    0.191434  0.031560\nage - smoke           0.238160   0.234431    0.191429  0.033607\nage - alco            0.238159   0.234429    0.191428  0.031622\nage                   0.238159   0.234429    0.191428  0.033160\nage - gender          0.238157   0.234426    0.191426  0.029552\n...                        ...        ...         ...       ...\ngender - ap_lo       -0.065701  -0.351237   -0.308611  0.074321\nheight - ap_lo       -0.066145  -0.283236   -0.234295  0.046793\ngender - cholesterol -0.173536  -0.152034   -0.142788  0.021345\ngender - weight      -0.182231  -0.183554   -0.151578  0.017849\nheight - weight      -0.188456  -0.196480   -0.162349  0.020684\n\n[66 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pearsonr</th>\n      <th>spearmanr</th>\n      <th>kendalltau</th>\n      <th>mu_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age - active</th>\n      <td>0.238165</td>\n      <td>0.234437</td>\n      <td>0.191434</td>\n      <td>0.031560</td>\n    </tr>\n    <tr>\n      <th>age - smoke</th>\n      <td>0.238160</td>\n      <td>0.234431</td>\n      <td>0.191429</td>\n      <td>0.033607</td>\n    </tr>\n    <tr>\n      <th>age - alco</th>\n      <td>0.238159</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.031622</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.238159</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.033160</td>\n    </tr>\n    <tr>\n      <th>age - gender</th>\n      <td>0.238157</td>\n      <td>0.234426</td>\n      <td>0.191426</td>\n      <td>0.029552</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>gender - ap_lo</th>\n      <td>-0.065701</td>\n      <td>-0.351237</td>\n      <td>-0.308611</td>\n      <td>0.074321</td>\n    </tr>\n    <tr>\n      <th>height - ap_lo</th>\n      <td>-0.066145</td>\n      <td>-0.283236</td>\n      <td>-0.234295</td>\n      <td>0.046793</td>\n    </tr>\n    <tr>\n      <th>gender - cholesterol</th>\n      <td>-0.173536</td>\n      <td>-0.152034</td>\n      <td>-0.142788</td>\n      <td>0.021345</td>\n    </tr>\n    <tr>\n      <th>gender - weight</th>\n      <td>-0.182231</td>\n      <td>-0.183554</td>\n      <td>-0.151578</td>\n      <td>0.017849</td>\n    </tr>\n    <tr>\n      <th>height - weight</th>\n      <td>-0.188456</td>\n      <td>-0.196480</td>\n      <td>-0.162349</td>\n      <td>0.020684</td>\n    </tr>\n  </tbody>\n</table>\n<p>66 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Log","metadata":{}},{"cell_type":"code","source":"df_gen4 = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).log()\ndf_gen4 = df_gen4.fillna(0)\ndf_gen4.replace([np.inf, -np.inf], 10e9, inplace=True)\ncorr = Correlations(df_gen4[df_gen4.columns[:-1]], df_gen4['cardio'])\ncor_df4 = corr.full_corr(mode='classification')\ncor_df4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:22:41.543857Z","iopub.execute_input":"2025-12-13T11:22:41.544590Z","iopub.status.idle":"2025-12-13T11:22:50.213311Z","shell.execute_reply.started":"2025-12-13T11:22:41.544564Z","shell.execute_reply":"2025-12-13T11:22:50.212371Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"                 pearsonr  spearmanr  kendalltau   mu_info\nlog ap_hi        0.290687   0.451885    0.401699  0.121887\nage              0.238159   0.234429    0.191428  0.032187\nlog age          0.237071   0.234429    0.191428  0.032623\ncholesterol      0.221147   0.215117    0.208824  0.031707\nlog cholesterol  0.219603   0.215117    0.208824  0.024703\nlog weight       0.184254   0.182701    0.150995  0.017194\nweight           0.181660   0.182701    0.150995  0.018246\nlog gluc         0.090940   0.091488    0.089827  0.007219\ngluc             0.089307   0.091488    0.089827  0.010020\nap_lo            0.065719   0.362572    0.332897  0.072845\nap_hi            0.054475   0.451885    0.401699  0.121631\nlog gender       0.008109   0.008109    0.008109  0.002670\ngender           0.008109   0.008109    0.008109  0.004358\nalco            -0.007330  -0.007330   -0.007330  0.010420\nlog alco        -0.007330  -0.007330   -0.007330  0.000249\nlog ap_lo       -0.007414   0.362094    0.332458  0.073456\nlog height      -0.010624  -0.012383   -0.010315  0.000000\nheight          -0.010821  -0.012383   -0.010315  0.001536\nsmoke           -0.015486  -0.015486   -0.015486  0.007617\nlog smoke       -0.015486  -0.015486   -0.015486  0.001242\nactive          -0.035653  -0.035653   -0.035653  0.008862\nlog active      -0.035653  -0.035653   -0.035653  0.008387","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pearsonr</th>\n      <th>spearmanr</th>\n      <th>kendalltau</th>\n      <th>mu_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>log ap_hi</th>\n      <td>0.290687</td>\n      <td>0.451885</td>\n      <td>0.401699</td>\n      <td>0.121887</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.238159</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.032187</td>\n    </tr>\n    <tr>\n      <th>log age</th>\n      <td>0.237071</td>\n      <td>0.234429</td>\n      <td>0.191428</td>\n      <td>0.032623</td>\n    </tr>\n    <tr>\n      <th>cholesterol</th>\n      <td>0.221147</td>\n      <td>0.215117</td>\n      <td>0.208824</td>\n      <td>0.031707</td>\n    </tr>\n    <tr>\n      <th>log cholesterol</th>\n      <td>0.219603</td>\n      <td>0.215117</td>\n      <td>0.208824</td>\n      <td>0.024703</td>\n    </tr>\n    <tr>\n      <th>log weight</th>\n      <td>0.184254</td>\n      <td>0.182701</td>\n      <td>0.150995</td>\n      <td>0.017194</td>\n    </tr>\n    <tr>\n      <th>weight</th>\n      <td>0.181660</td>\n      <td>0.182701</td>\n      <td>0.150995</td>\n      <td>0.018246</td>\n    </tr>\n    <tr>\n      <th>log gluc</th>\n      <td>0.090940</td>\n      <td>0.091488</td>\n      <td>0.089827</td>\n      <td>0.007219</td>\n    </tr>\n    <tr>\n      <th>gluc</th>\n      <td>0.089307</td>\n      <td>0.091488</td>\n      <td>0.089827</td>\n      <td>0.010020</td>\n    </tr>\n    <tr>\n      <th>ap_lo</th>\n      <td>0.065719</td>\n      <td>0.362572</td>\n      <td>0.332897</td>\n      <td>0.072845</td>\n    </tr>\n    <tr>\n      <th>ap_hi</th>\n      <td>0.054475</td>\n      <td>0.451885</td>\n      <td>0.401699</td>\n      <td>0.121631</td>\n    </tr>\n    <tr>\n      <th>log gender</th>\n      <td>0.008109</td>\n      <td>0.008109</td>\n      <td>0.008109</td>\n      <td>0.002670</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>0.008109</td>\n      <td>0.008109</td>\n      <td>0.008109</td>\n      <td>0.004358</td>\n    </tr>\n    <tr>\n      <th>alco</th>\n      <td>-0.007330</td>\n      <td>-0.007330</td>\n      <td>-0.007330</td>\n      <td>0.010420</td>\n    </tr>\n    <tr>\n      <th>log alco</th>\n      <td>-0.007330</td>\n      <td>-0.007330</td>\n      <td>-0.007330</td>\n      <td>0.000249</td>\n    </tr>\n    <tr>\n      <th>log ap_lo</th>\n      <td>-0.007414</td>\n      <td>0.362094</td>\n      <td>0.332458</td>\n      <td>0.073456</td>\n    </tr>\n    <tr>\n      <th>log height</th>\n      <td>-0.010624</td>\n      <td>-0.012383</td>\n      <td>-0.010315</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>height</th>\n      <td>-0.010821</td>\n      <td>-0.012383</td>\n      <td>-0.010315</td>\n      <td>0.001536</td>\n    </tr>\n    <tr>\n      <th>smoke</th>\n      <td>-0.015486</td>\n      <td>-0.015486</td>\n      <td>-0.015486</td>\n      <td>0.007617</td>\n    </tr>\n    <tr>\n      <th>log smoke</th>\n      <td>-0.015486</td>\n      <td>-0.015486</td>\n      <td>-0.015486</td>\n      <td>0.001242</td>\n    </tr>\n    <tr>\n      <th>active</th>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>0.008862</td>\n    </tr>\n    <tr>\n      <th>log active</th>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>-0.035653</td>\n      <td>0.008387</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(heart2[heart2.columns[:-1]], heart['cardio']).exp()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(heart2[heart2.columns[:-1]], heart['cardio']).degree()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(heart2[heart2.columns[:-1]], heart['cardio']).devision_on_last_2()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"'multiply of - ap_hi cholesterol': 0.12868723012547956,\n 'ap_hi': 0.12198323105012188,\n 'multiply of - ap_hi ap_lo': 0.12012630609887065,\n 'multiply of - ap_hi gluc': 0.11764224083125385,\n 'multiply of - height ap_hi': 0.11645413883453792,\n 'multiply of - gender ap_hi': 0.11547996142741934,\n 'multiply of - age ap_hi': 0.11065677496669246,\n 'multiply of - ap_hi active': 0.10546168339602358,\n 'multiply of - weight ap_hi': 0.10001372310340795,\n 'multiply of - ap_lo cholesterol': 0.09105549758079867,\n 'multiply of - age ap_lo': 0.08670456372350466,\n 'ap_lo': 0.07551061014232241,\n 'multiply of - gender ap_lo': 0.07538714887498865,\n 'multiply of - ap_lo gluc': 0.07376476593987347,\n 'multiply of - weight ap_lo': 0.0719285541041863,\n 'multiply of - height ap_lo': 0.06763992499346316\n\n\n\n 'multiply of - gender ap_hi cholesterol': 0.12642497401288,\n 'multiply of - ap_hi ap_lo cholesterol': 0.12545853324937428,\n 'multiply of - ap_hi cholesterol gluc': 0.12432499530081875,\n 'multiply of - height ap_hi cholesterol': 0.12229630186528717,\n 'ap_hi': 0.12140187751284182,\n 'multiply of - age ap_hi ap_lo': 0.11790270802617608,\n 'multiply of - gender ap_hi gluc': 0.11589606815414855,\n 'multiply of - ap_hi ap_lo gluc': 0.1156998028947478,\n 'multiply of - height ap_hi gluc': 0.11425469929383314,\n 'multiply of - gender height ap_hi': 0.11269482570743627,\n 'multiply of - ap_hi cholesterol active': 0.11102680594378822,\n 'multiply of - gender ap_hi ap_lo': 0.11101527069697248,\n 'multiply of - height ap_hi ap_lo': 0.11096273853804406,\n 'multiply of - age ap_hi cholesterol': 0.11042740001336715,\n 'multiply of - weight ap_hi cholesterol': 0.1094161010929422,\n 'multiply of - weight ap_hi ap_lo': 0.10857167600496864,\n 'multiply of - ap_hi gluc active': 0.1030877749085315,\n 'multiply of - age ap_hi gluc': 0.10066613393303792,\n 'multiply of - age height ap_hi': 0.09914599666884416,\n 'multiply of - ap_hi ap_lo active': 0.0987815103799059,\n 'multiply of - height ap_hi active': 0.09717783472266173,\n 'multiply of - gender ap_hi active': 0.09700145061052501\n\n ","metadata":{}},{"cell_type":"code","source":"def train_test_scaller(df, name=''):\n    \n    y = df[name]\n    X = df.drop([name], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=99)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    return X_train, X_test, y_train, y_test\n\ndef auto_trainer(X_train, X_test, y_train, y_test):\n    clf = RandomForestClassifier(n_estimators=13, max_depth=5, random_state=42).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    y_pred_train = clf.predict(X_train)\n    #y_pred_proba = clf.predict_proba(X_test[:2, :])\n    clf.score(X_test, y_test)\n   \n    print('Report on test data')\n    print(classification_report(y_test, y_pred))\n    cf_matrix = confusion_matrix(y_test, y_pred)\n\n    print('Report on train data')\n    print(classification_report(y_train, y_pred_train))\n    cf_matrix = confusion_matrix(y_train, y_pred_train)\n    print(cf_matrix)\n\ndef feature_gen(df_gen, target_name, threshold=0.1): \n   ## add some chose\n    corr = Correlations(df_gen[df_gen.columns[:-1]], df_gen[target_name])\n    cor_dict = corr.corr_feature_analisys()\n    mi = corr.mutual_info()\n    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n    mi_lim_ex = [col for col in mi_lim.keys() if col in df_gen.columns]\n    df_gen = df_gen.drop(columns=mi_lim_ex, axis=1)\n    return df_gen\n\ndef simple_pipe(df_inner, df_gen, target_name, threshold):\n    ndf = feature_gen(df_gen, target_name, threshold)\n    X_train, X_test, y_train, y_test = train_test_scaller(df_inner, name=target_name)\n    print('W/O manipulations')\n    auto_trainer(X_train, X_test, y_train, y_test)\n    print('With manipulations')\n    X_train, X_test, y_train, y_test = train_test_scaller(ndf, name=target_name)\n    auto_trainer(X_train, X_test, y_train, y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:39:28.904314Z","iopub.execute_input":"2025-12-04T13:39:28.904923Z","iopub.status.idle":"2025-12-04T13:39:28.916698Z","shell.execute_reply.started":"2025-12-04T13:39:28.904894Z","shell.execute_reply":"2025-12-04T13:39:28.915562Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df_gen = Generator(heart[heart.columns[:-1]], heart['DEATH_EVENT']).multiply(by=2)\nsimple_pipe(heart, df_gen, 'DEATH_EVENT', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:39:34.332909Z","iopub.execute_input":"2025-12-04T13:39:34.333216Z","iopub.status.idle":"2025-12-04T13:39:35.812541Z","shell.execute_reply.started":"2025-12-04T13:39:34.333185Z","shell.execute_reply":"2025-12-04T13:39:35.811718Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88        52\n           1       0.74      0.74      0.74        23\n\n    accuracy                           0.84        75\n   macro avg       0.81      0.81      0.81        75\nweighted avg       0.84      0.84      0.84        75\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.99      0.96       151\n           1       0.97      0.85      0.91        73\n\n    accuracy                           0.94       224\n   macro avg       0.95      0.92      0.93       224\nweighted avg       0.94      0.94      0.94       224\n\n[[149   2]\n [ 11  62]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92        52\n           1       0.89      0.70      0.78        23\n\n    accuracy                           0.88        75\n   macro avg       0.88      0.83      0.85        75\nweighted avg       0.88      0.88      0.88        75\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.96       151\n           1       1.00      0.85      0.92        73\n\n    accuracy                           0.95       224\n   macro avg       0.97      0.92      0.94       224\nweighted avg       0.95      0.95      0.95       224\n\n[[151   0]\n [ 11  62]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_gen = Generator(person[person.columns[:-1]], person['Personality']).multiply(by=2)\nsimple_pipe(person, df_gen, 'Personality', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:45:30.267054Z","iopub.execute_input":"2025-12-04T13:45:30.267367Z","iopub.status.idle":"2025-12-04T13:45:31.045069Z","shell.execute_reply.started":"2025-12-04T13:45:30.267343Z","shell.execute_reply":"2025-12-04T13:45:31.044153Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.92      0.92      0.92       342\n           1       0.93      0.92      0.93       383\n\n    accuracy                           0.92       725\n   macro avg       0.92      0.92      0.92       725\nweighted avg       0.92      0.92      0.92       725\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94      1067\n           1       0.95      0.93      0.94      1108\n\n    accuracy                           0.94      2175\n   macro avg       0.94      0.94      0.94      2175\nweighted avg       0.94      0.94      0.94      2175\n\n[[1015   52]\n [  82 1026]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.92      0.92      0.92       342\n           1       0.93      0.92      0.93       383\n\n    accuracy                           0.92       725\n   macro avg       0.92      0.92      0.92       725\nweighted avg       0.92      0.92      0.92       725\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94      1067\n           1       0.95      0.93      0.94      1108\n\n    accuracy                           0.94      2175\n   macro avg       0.94      0.94      0.94      2175\nweighted avg       0.94      0.94      0.94      2175\n\n[[1015   52]\n [  82 1026]]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"df_gen = Generator(iris[iris.columns[:-1]], iris['Species']).multiply(by=2)\nsimple_pipe(iris, df_gen, 'Species', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:48:05.457625Z","iopub.execute_input":"2025-12-04T13:48:05.457927Z","iopub.status.idle":"2025-12-04T13:48:05.617826Z","shell.execute_reply.started":"2025-12-04T13:48:05.457902Z","shell.execute_reply":"2025-12-04T13:48:05.616930Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.93      0.93      0.93        14\n           2       0.92      0.92      0.92        12\n\n    accuracy                           0.95        38\n   macro avg       0.95      0.95      0.95        38\nweighted avg       0.95      0.95      0.95        38\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       1.00      1.00      1.00        36\n           2       1.00      1.00      1.00        38\n\n    accuracy                           1.00       112\n   macro avg       1.00      1.00      1.00       112\nweighted avg       1.00      1.00      1.00       112\n\n[[38  0  0]\n [ 0 36  0]\n [ 0  0 38]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.93      0.93      0.93        14\n           2       0.92      0.92      0.92        12\n\n    accuracy                           0.95        38\n   macro avg       0.95      0.95      0.95        38\nweighted avg       0.95      0.95      0.95        38\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       1.00      1.00      1.00        36\n           2       1.00      1.00      1.00        38\n\n    accuracy                           1.00       112\n   macro avg       1.00      1.00      1.00       112\nweighted avg       1.00      1.00      1.00       112\n\n[[38  0  0]\n [ 0 36  0]\n [ 0  0 38]]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df_gen = Generator(marketing[marketing.columns[:-1]], marketing['responded']).multiply(by=2)\nsimple_pipe(marketing, df_gen, 'responded', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:07:09.360381Z","iopub.execute_input":"2025-12-04T14:07:09.360695Z","iopub.status.idle":"2025-12-04T14:07:09.740563Z","shell.execute_reply.started":"2025-12-04T14:07:09.360673Z","shell.execute_reply":"2025-12-04T14:07:09.739693Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00         7\n         2.0       1.00      1.00      1.00         7\n\n    accuracy                           1.00        14\n   macro avg       1.00      1.00      1.00        14\nweighted avg       1.00      1.00      1.00        14\n\nReport on train data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00        21\n         2.0       1.00      1.00      1.00        21\n\n    accuracy                           1.00        42\n   macro avg       1.00      1.00      1.00        42\nweighted avg       1.00      1.00      1.00        42\n\n[[21  0]\n [ 0 21]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00         7\n         2.0       1.00      1.00      1.00         7\n\n    accuracy                           1.00        14\n   macro avg       1.00      1.00      1.00        14\nweighted avg       1.00      1.00      1.00        14\n\nReport on train data\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00        21\n         2.0       1.00      1.00      1.00        21\n\n    accuracy                           1.00        42\n   macro avg       1.00      1.00      1.00        42\nweighted avg       1.00      1.00      1.00        42\n\n[[21  0]\n [ 0 21]]\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"df_gen = Generator(bankruptcy[bankruptcy.columns[:-1]], bankruptcy['Bankrupt?']).multiply(by=2)\nsimple_pipe(bankruptcy, df_gen, 'Bankrupt?', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:10:53.771744Z","iopub.execute_input":"2025-12-04T14:10:53.772086Z","iopub.status.idle":"2025-12-04T14:23:39.429738Z","shell.execute_reply.started":"2025-12-04T14:10:53.772061Z","shell.execute_reply":"2025-12-04T14:23:39.428579Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_38/2262713051.py:262: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  stat, _ = stats.pearsonr(self.X[pairs[0]], self.X[pairs[1]])\n/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:4638: RuntimeWarning: invalid value encountered in less\n  nconst_y = xp.any(normym < threshold*xp.abs(ymean), axis=axis)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:354: RuntimeWarning: invalid value encountered in less\n  ia = (out < a) | xp.isnan(a)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:361: RuntimeWarning: invalid value encountered in greater\n  ib = (out > b) | xp.isnan(b)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/3034656358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbankruptcy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbankruptcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbankruptcy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bankrupt?'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbankruptcy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bankrupt?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36msimple_pipe\u001b[0;34m(df_inner, df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_scaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W/O manipulations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36mfeature_gen\u001b[0;34m(df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m    \u001b[0;31m## add some chose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_feature_analisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# exclude columns with have a mu info with target less than 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/2262713051.py\u001b[0m in \u001b[0;36mcorr_feature_analisys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mcor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[1;32m   4636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4637\u001b[0m     \u001b[0mnconst_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormxm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4638\u001b[0;31m     \u001b[0mnconst_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormym\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4639\u001b[0m     \u001b[0mnconst_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnconst_x\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnconst_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnconst_xy\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mconst_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_any_dispatcher\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m def _any_dispatcher(a, axis=None, out=None, keepdims=None, *,\n\u001b[0m\u001b[1;32m   2318\u001b[0m                     where=np._NoValue):\n\u001b[1;32m   2319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":61},{"cell_type":"code","source":"df_gen = Generator(heart2[heart2.columns[:-1]], heart2['cardio']).multiply(by=2)\nsimple_pipe(heart2, df_gen, 'cardio', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:30:41.694348Z","iopub.execute_input":"2025-12-04T14:30:41.694670Z","iopub.status.idle":"2025-12-04T14:31:23.109821Z","shell.execute_reply.started":"2025-12-04T14:30:41.694621Z","shell.execute_reply":"2025-12-04T14:31:23.108833Z"}},"outputs":[{"name":"stdout","text":"W/O manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75      8705\n           1       0.77      0.67      0.72      8795\n\n    accuracy                           0.73     17500\n   macro avg       0.74      0.73      0.73     17500\nweighted avg       0.74      0.73      0.73     17500\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.70      0.80      0.75     26316\n           1       0.76      0.66      0.71     26184\n\n    accuracy                           0.73     52500\n   macro avg       0.73      0.73      0.73     52500\nweighted avg       0.73      0.73      0.73     52500\n\n[[20924  5392]\n [ 8844 17340]]\nWith manipulations\nReport on test data\n              precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75      8705\n           1       0.77      0.68      0.72      8795\n\n    accuracy                           0.73     17500\n   macro avg       0.74      0.73      0.73     17500\nweighted avg       0.74      0.73      0.73     17500\n\nReport on train data\n              precision    recall  f1-score   support\n\n           0       0.70      0.79      0.74     26316\n           1       0.76      0.66      0.71     26184\n\n    accuracy                           0.73     52500\n   macro avg       0.73      0.73      0.73     52500\nweighted avg       0.73      0.73      0.73     52500\n\n[[20824  5492]\n [ 8800 17384]]\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"df_gen = Generator(onlinefraud[onlinefraud.columns[:-1]], onlinefraud['isFraud']).multiply(by=2)\nsimple_pipe(onlinefraud, df_gen, 'isFraud', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:32:18.070217Z","iopub.execute_input":"2025-12-04T14:32:18.070530Z","execution_failed":"2025-12-05T05:57:01.261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(creditfraud[onlinefraud.columns[:-1]], onlinefraud['Class']).multiply(by=2)\nsimple_pipe(onlinefraud, df_gen, 'Class', 0.1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-05T05:57:01.271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(bankruptcy[bankruptcy.columns[:-1]], bankruptcy['Bankrupt?']).multiply(by=2)\nsimple_pipe(bankruptcy, df_gen, 'Bankrupt?', 0.1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_test_scaller(df, name=''):\n    \n    y = df[name]\n    X = df.drop([name], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=99)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    return X_train, X_test, y_train, y_test\n\ndef auto_trainer(X_train, X_test, y_train, y_test):\n    clf = RandomForestRegressor(n_estimators=13, max_depth=5, random_state=42).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    y_pred_train = clf.predict(X_train)\n    #y_pred_proba = clf.predict_proba(X_test[:2, :])\n    clf.score(X_test, y_test)\n   \n    print('Report on test data')\n    print(classification_report(y_test, y_pred))\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    #plt.figure()\n    #sns.heatmap(cf_matrix, annot=True)\n    #$print(cf_matrix)\n    \n    print('Report on train data')\n    print(classification_report(y_train, y_pred_train))\n    cf_matrix = confusion_matrix(y_train, y_pred_train)\n    print(cf_matrix)\n    #plt.figure()\n    #sns.heatmap(cf_matrix, annot=True)\n\n\n#def feature_gen(df_inner, target_name, threshold=0.1): \n#    df = Generator(df_inner[df_inner.columns[:-1]], df_inner[target_name]).multiply(by=2) ## add some chose\n#    corr = Correlations(df[df.columns[:-1]], df[target_name])\n#    cor_dict = corr.corr_feature_analisys()\n#    mi = corr.mutual_info()\n#    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n#    mi_lim_ex = [col for col in mi_lim.keys() if col in df.columns]\n#    df = df.drop(columns=mi_lim_ex, axis=1)\n#    return df\n\n#df_gen = Generator(heart[heart.columns[:-1]], heart['DEATH_EVENT']).multiply(by=2)\ndef feature_gen(df_gen, target_name, threshold=0.1): \n   ## add some chose\n    corr = Correlations(df_gen[df_gen.columns[:-1]], df_gen[target_name])\n    cor_dict = corr.corr_feature_analisys()\n    mi = corr.mutual_info()\n    mi_lim = {k:v for k, v in mi.items() if v < threshold} # exclude columns with have a mu info with target less than 0.1\n    mi_lim_ex = [col for col in mi_lim.keys() if col in df_gen.columns]\n    df_gen = df_gen.drop(columns=mi_lim_ex, axis=1)\n    return df_gen\n\ndef simple_pipe(df_inner, df_gen, target_name, threshold):\n    ndf = feature_gen(df_gen, target_name, threshold)\n    X_train, X_test, y_train, y_test = train_test_scaller(df_inner, name=target_name)\n    print('W/O manipulations')\n    auto_trainer(X_train, X_test, y_train, y_test)\n    print('With manipulations')\n    X_train, X_test, y_train, y_test = train_test_scaller(ndf, name=target_name)\n    auto_trainer(X_train, X_test, y_train, y_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_gen = Generator(student[student.columns[:-1]], student['exam_score']).multiply(by=2)\nsimple_pipe(student, df_gen, 'exam_score', 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:59:33.931988Z","iopub.execute_input":"2025-12-04T13:59:33.932232Z","iopub.status.idle":"2025-12-04T13:59:36.355496Z","shell.execute_reply.started":"2025-12-04T13:59:33.932210Z","shell.execute_reply":"2025-12-04T13:59:36.354241Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:4637: RuntimeWarning: invalid value encountered in less\n  nconst_x = xp.any(normxm < threshold*xp.abs(xmean), axis=axis)\n/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:4638: RuntimeWarning: invalid value encountered in less\n  nconst_y = xp.any(normym < threshold*xp.abs(ymean), axis=axis)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:354: RuntimeWarning: invalid value encountered in less\n  ia = (out < a) | xp.isnan(a)\n/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/common/_aliases.py:361: RuntimeWarning: invalid value encountered in greater\n  ib = (out > b) | xp.isnan(b)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/4221916904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exam_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exam_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36msimple_pipe\u001b[0;34m(df_inner, df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_scaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W/O manipulations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/1023634016.py\u001b[0m in \u001b[0;36mfeature_gen\u001b[0;34m(df_gen, target_name, threshold)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mcor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_feature_analisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmi_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# exclude columns with have a mu info with target less than 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmi_lim_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmi_lim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/2262713051.py\u001b[0m in \u001b[0;36mmutual_info\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mnames_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'regression'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m              \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    386\u001b[0m            \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbl\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPeredachi\u001b[0m \u001b[0mInf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1987\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_estimate_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    253\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN."],"ename":"ValueError","evalue":"Input X contains NaN.","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"student['gender'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:57:00.855761Z","iopub.execute_input":"2025-12-04T13:57:00.856487Z","iopub.status.idle":"2025-12-04T13:57:00.862211Z","shell.execute_reply.started":"2025-12-04T13:57:00.856453Z","shell.execute_reply":"2025-12-04T13:57:00.861227Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"array([1, 2, 'Other'], dtype=object)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"df = feature_gen(iris, 'Personality')\nX_train, X_test, y_train, y_test = train_test_scaller(df, name='Personality')\nauto_trainer(X_train, X_test, y_train, y_test )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}